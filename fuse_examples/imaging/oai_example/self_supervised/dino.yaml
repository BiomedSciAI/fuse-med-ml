experiment : dino_oai
cache_name : DESS_TSE_cache
model_dir : /oai/results/
csv_path : /oai/code/data/relevant_dicoms.csv
clearml_project_name : OAI/Dino #Liver/Dino

resize_to : [224,224] #[40, 512, 512] # only resize if for_classification flag is true (validation)
batch_size : 4 #10 for res18, 4 for vit
batch_size_eval : 8
precision : 32

reset_cache : False
debug : False
train_acc: False
im2D : True

n_workers : 16
backbone : unet3d
pretrained: False
pretrained_pth : null # if pretrained=True a path need to be filled. can download from https://github.com/MrGiovanni/SuPreM
ckpt_pth : no_path

patch_shape : [4,16,16] # for vit
projection: 2048

momentum_teacher : 0.9995
n_crops : 4 # 4, orig Dino 6 local 2 global
out_dim : 512
cls_dim: 256
n_epochs : 70
learning_rate :  0.001 #0.004
cls_learning_rate : 0.0001
clip_grad : 3.0
warmup_teacher_temp : 0.04
warmup_teacher_temp_epochs : 0
teacher_temp : 0.04
student_temp : 0.1
weight_decay : 0.04
weight_decay_end : 0.4 #Final value of the weight decay. We use a cosine schedule for WD and using a larger decay by the end of training improves performance for ViTs.
norm_last_layer : True
use_bn_in_head : False #Whether to use batch normalizations in projection head (Default: False)
freeze_last_layer : 1 #Number of epochs during which we keep the output layer fixed. Typically doing so during the first epoch helps training. Try increasing this value if the loss does not decrease.

clearml : True
