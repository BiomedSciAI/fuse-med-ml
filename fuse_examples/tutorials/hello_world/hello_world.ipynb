{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FuseMedML - Hello World\n",
    "[![Github repo](https://img.shields.io/static/v1?label=GitHub&message=FuseMedML&color=brightgreen)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/fuse-med-ml.svg)](https://badge.fury.io/py/fuse-med-ml)\n",
    "\n",
    "[![Slack channel](https://img.shields.io/badge/support-slack-slack.svg?logo=slack)](https://join.slack.com/t/fusemedml/shared_invite/zt-xr1jaj29-h7IMsSc0Lq4qpVNxW97Phw)\n",
    "\n",
    "[![Open Source](https://badges.frapsoft.com/os/v1/open-source.svg)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "\n",
    "**Welcome to Fuse's 'hello world' hands-on notebook!**\n",
    "\n",
    "In this notebook we'll examine a FuseMedML's basic use case: MNIST multiclass classification - incluing training, inference and evaluation.\n",
    "\n",
    "FuseMedML is an open-source python-based framework designed to enhance collaboration and accelerate discoveries in Fused Medical data through advanced Machine Learning technologies. \n",
    "\n",
    "Initial version is PyTorch-based and focuses on deep learning on medical imaging.\n",
    "\n",
    "By the end of the session we hope you'll be familiar with basic Fuse's workflow and acknowledge it's potential.\n",
    "\n",
    "Open and run this notebook in [Google Colab](https://colab.research.google.com/github/IBM/fuse-med-ml/blob/master/fuse_examples/tutorials/hello_world/hello_world.ipynb)\n",
    "\n",
    "ENJOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## **Installation Details - Google Colab**\n",
    "\n",
    "\n",
    "#### **Install FuseMedML**\n",
    "\\- If fuse-med-ml package is already cloned and installed this should be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Setup environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import OrderedDict\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from fuse.eval.evaluator import EvaluatorDefault\n",
    "from fuse.data.dataset.dataset_wrapper import FuseDatasetWrapper\n",
    "from fuse.data.sampler.sampler_balanced_batch import FuseSamplerBalancedBatch\n",
    "from fuse.losses.loss_default import FuseLossDefault\n",
    "from fuse.managers.callbacks.callback_tensorboard import FuseTensorboardCallback\n",
    "from fuse.managers.manager_default import FuseManagerDefault\n",
    "from fuse.eval.metrics.classification.metrics_classification_common import MetricAccuracy, MetricAUCROC, MetricROCCurve\n",
    "from fuse.eval.metrics.classification.metrics_thresholding_common import MetricApplyThresholds\n",
    "from fuse.models.model_wrapper import FuseModelWrapper\n",
    "from fuse_examples.tutorials.hello_world.hello_world_utils import LeNet, perform_softmax\n",
    "import fuse.utils.gpu as FuseUtilsGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "NUM_GPUS = 1\n",
    "force_gpus = [0]\n",
    "FuseUtilsGPU.choose_and_enable_multiple_gpus(NUM_GPUS, force_gpus=force_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Output paths**\n",
    "The user is able to customize the output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'examples'\n",
    "PATHS = {'model_dir': os.path.join(ROOT, 'mnist/model_dir'),\n",
    "         'force_reset_model_dir': True,  # If True will reset model dir automatically - otherwise will prompt 'are you sure' message.\n",
    "         'cache_dir': os.path.join(ROOT, 'mnist/cache_dir'),\n",
    "         'inference_dir': os.path.join(ROOT, 'mnist/infer_dir'),\n",
    "         'eval_dir': os.path.join(ROOT, 'mnist/eval_dir')}\n",
    "\n",
    "paths = PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training Parameters**\n",
    "* Model - which model we are using.\n",
    "* Data - define parameters for the data preproccesing.\n",
    "* Manager - define parameters for the training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COMMON_PARAMS = {}\n",
    "\n",
    "### Model ###\n",
    "TRAIN_COMMON_PARAMS['model'] = 'lenet'\n",
    "\n",
    "### Data ###\n",
    "TRAIN_COMMON_PARAMS['data.batch_size'] = 100\n",
    "TRAIN_COMMON_PARAMS['data.train_num_workers'] = 8\n",
    "TRAIN_COMMON_PARAMS['data.validation_num_workers'] = 8\n",
    "\n",
    "### Manager ###\n",
    "TRAIN_COMMON_PARAMS['manager.train_params'] = {\n",
    "    'num_epochs': 5,\n",
    "    'virtual_batch_size': 1,  # number of batches in one virtual batch\n",
    "    'start_saving_epochs': 10,  # first epoch to start saving checkpoints from\n",
    "    'gap_between_saving_epochs': 5,  # number of epochs between saved checkpoint\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.best_epoch_source'] = {\n",
    "    'source': 'metrics.accuracy',  # can be any key from 'epoch_results'\n",
    "    'optimization': 'max',  # can be either min/max\n",
    "    'on_equal_values': 'better',\n",
    "    # can be either better/worse - whether to consider best epoch when values are equal\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.learning_rate'] = 1e-4\n",
    "TRAIN_COMMON_PARAMS['manager.weight_decay'] = 0.001\n",
    "TRAIN_COMMON_PARAMS['manager.resume_checkpoint_filename'] = None  # if not None, will try to load the checkpoint\n",
    "\n",
    "train_params = TRAIN_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data**\n",
    "Downloading the MNIST dataset and building dataloaders (torch.utils.data.DataLoader) for both train and validation using Fuse components:\n",
    "1. Wrapper - **FuseDatasetWrapper**:\n",
    "\n",
    "    Wraps PyTorch dataset such that each sample is being converted to dictionary according to the provided mapping.\n",
    "2. Sampler - **FuseSamplerBalancedBatch**:\n",
    "\n",
    "    Implementing 'torch.utils.data.sampler'.\n",
    "    \n",
    "    The sampler creates a balanced batch comprised of an equal number of samples per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "torch_train_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=True, transform=transform)\n",
    "\n",
    "# wrapping torch dataset\n",
    "train_dataset = FuseDatasetWrapper(name='train', dataset=torch_train_dataset, mapping=('image', 'label'))\n",
    "train_dataset.create()\n",
    "\n",
    "sampler = FuseSamplerBalancedBatch(dataset=train_dataset,\n",
    "                                balanced_class_name='data.label',\n",
    "                                num_balanced_classes=10,\n",
    "                                batch_size=train_params['data.batch_size'],\n",
    "                                balanced_class_weights=None)\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=train_params['data.train_num_workers'])\n",
    "\n",
    "## Validation data\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=train_params['data.batch_size'],\n",
    "                                num_workers=train_params['data.validation_num_workers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**\n",
    "Building the LeNet model using PyTorch's API and then wrapping it. \n",
    "\n",
    "The model outputs will be aggregated in batch_dict['model.*']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = LeNet()\n",
    "\n",
    "model = FuseModelWrapper(model=torch_model,\n",
    "                        model_inputs=['data.image'],\n",
    "                        post_forward_processing_function=perform_softmax,\n",
    "                        model_outputs=['logits.classification', 'output.classification']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loss function**\n",
    "Dictionary of loss elements. each element is a sub-class of FuseLossBase.\n",
    "\n",
    "The total loss will be the weighted sum of all the elements.\n",
    "\n",
    "Fuse's loss API extracts the predications and the labels from the dictonary hierarchy and then applies the callable loss function while considering the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    'cls_loss': FuseLossDefault(pred_name='model.logits.classification', target_name='data.label', callable=F.cross_entropy, weight=1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Metrics**\n",
    "Dictionary of metric elements. Each element is a sub-class of FuseMetricBase.\n",
    "\n",
    "The metrics will be calculated per epoch for both the validation and train.\n",
    "\n",
    "The 'best_epoch_source', used to save the best model could be based on one of these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = OrderedDict([\n",
    "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')), # will apply argmax\n",
    "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred', target='data.label'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Callbacks**\n",
    "Callbacks are sub-classes of FuseCallbackBase.\n",
    "\n",
    "A callback is an object that can preform actions at various stages of training.\n",
    "\n",
    "In each stage it allows to manipulate either the data, batch_dict or epoch_results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    FuseTensorboardCallback(model_dir=paths['model_dir']),  # save statistics for tensorboard\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**\n",
    "Building Fuse's manager and supplying it PyTorch's optimizer and scheduler.\n",
    "\n",
    "Possible workflows are listed in the FuseMangerDefault's documentation.\n",
    "\n",
    "Note that the manger is using the training paremeter that we've set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_params['manager.learning_rate'], weight_decay=train_params['manager.weight_decay'])\n",
    "\n",
    "# create scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# train from scratch\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "\n",
    "# Providing the objects required for the training process.\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_params['manager.train_params'])\n",
    "\n",
    "# manager.set_device('cpu') # uncomment to use cpu\n",
    "\n",
    "# Start training\n",
    "manager.train(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Infer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_COMMON_PARAMS = {}\n",
    "INFER_COMMON_PARAMS['infer_filename'] = 'validation_set_infer.gz'\n",
    "INFER_COMMON_PARAMS['checkpoint'] = 'best' \n",
    "\n",
    "infer_common_params = INFER_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Infer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(dataset=validation_dataset, collate_fn=validation_dataset.collate_fn, batch_size=2, num_workers=2)\n",
    "\n",
    "## Manager for inference\n",
    "manager = FuseManagerDefault()\n",
    "# manager.set_device('cpu') # uncomment to use cpu\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**\n",
    "Using the Evaluator from the evaluation package of FuseMedML (fuse.eval) which is a standalone library for evaluating ML models that not necessarily trained with FuseMedML.\n",
    "\n",
    "More details and examples for the evaluation package can be found [here](https://github.com/IBM/fuse-med-ml/blob/master/fuse/eval/README.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define EVAL Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_COMMON_PARAMS = {}\n",
    "EVAL_COMMON_PARAMS['infer_filename'] = INFER_COMMON_PARAMS['infer_filename']\n",
    "eval_common_params = EVAL_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Calculate metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "# metrics\n",
    "metrics = OrderedDict([\n",
    "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')), # will apply argmax\n",
    "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred', target='data.label')),\n",
    "    ('roc', MetricROCCurve(pred='model.output.classification', target='data.label', class_names=class_names, output_filename=os.path.join(paths['inference_dir'], 'roc_curve.png'))),\n",
    "    ('auc', MetricAUCROC(pred='model.output.classification', target='data.label', class_names=class_names)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evaluator\n",
    "evaluator = EvaluatorDefault()\n",
    "\n",
    "# run\n",
    "results = evaluator.eval(ids=None,\n",
    "                data=os.path.join(paths[\"inference_dir\"], eval_common_params[\"infer_filename\"]),\n",
    "                metrics=metrics,\n",
    "                output_dir=paths['eval_dir'])\n",
    "\n",
    "# For testing purposes\n",
    "test_result_acc = results['metrics.accuracy']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598f6cce495816406fbd34fea65bf7c807885b1496bf9be8c5dc5b47eac7d159"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38_tf2.3_pytorch1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
