{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## Installation Details - Google Colab\n",
    "\n",
    "### **Enable GPU Support**\n",
    "\n",
    "To use GPU through Google Colab, change the runtime mode to GPU:\n",
    "\n",
    "From the \"Runtime\" menu select \"Change Runtime Type\", choose \"GPU\" from the drop-down menu and click \"SAVE\"\n",
    "When asked, reboot the system.\n",
    "\n",
    "### **Install FuseMedML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/fuse-med-ml.git\n",
    "# %cd fuse-med-ml\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from fuse.analyzer.analyzer_default import FuseAnalyzerDefault\n",
    "from fuse.data.dataset.dataset_wrapper import FuseDatasetWrapper\n",
    "from fuse.data.sampler.sampler_balanced_batch import FuseSamplerBalancedBatch\n",
    "from fuse.losses.loss_default import FuseLossDefault\n",
    "from fuse.managers.callbacks.callback_metric_statistics import FuseMetricStatisticsCallback\n",
    "from fuse.managers.callbacks.callback_tensorboard import FuseTensorboardCallback\n",
    "from fuse.managers.callbacks.callback_time_statistics import FuseTimeStatisticsCallback\n",
    "from fuse.managers.manager_default import FuseManagerDefault\n",
    "from fuse.metrics.classification.metric_accuracy import FuseMetricAccuracy\n",
    "from fuse.metrics.classification.metric_auc import FuseMetricAUC\n",
    "from fuse.metrics.classification.metric_roc_curve import FuseMetricROCCurve\n",
    "from fuse.models.model_wrapper import FuseModelWrapper\n",
    "from fuse.utils.utils_debug import FuseUtilsDebug\n",
    "from fuse.utils.utils_gpu import FuseUtilsGPU\n",
    "from fuse.utils.utils_logger import fuse_logger_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup environment**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Debugger**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;21m(utils_misc.py:280) WARNING: Ignoring a redefinition of the singleton of class {class_.__name__}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mode = 'default'  # Options: 'default', 'fast', 'debug', 'verbose', 'user'. See details in FuseUtilsDebug\n",
    "debug = FuseUtilsDebug(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Output paths**\n",
    "TODO: elaborate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'fuse_examples' # TODO: fill path here\n",
    "PATHS = {'model_dir': os.path.join(ROOT, 'mnist/model_dir'),\n",
    "         'force_reset_model_dir': True,  # If True will reset model dir automatically - otherwise will prompt 'are you sure' message.\n",
    "         'cache_dir': os.path.join(ROOT, 'mnist/cache_dir'),\n",
    "         'inference_dir': os.path.join(ROOT, 'mnist/infer_dir'),\n",
    "         'analyze_dir': os.path.join(ROOT, 'mnist/analyze_dir')}\n",
    "\n",
    "paths = PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Train Common Params**\n",
    "TODO: elaborate: what is the use of those params? common options? how it serves the user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============\n",
    "# Data\n",
    "# ============\n",
    "TRAIN_COMMON_PARAMS = {}\n",
    "TRAIN_COMMON_PARAMS['data.batch_size'] = 30\n",
    "TRAIN_COMMON_PARAMS['data.train_num_workers'] = 8\n",
    "TRAIN_COMMON_PARAMS['data.validation_num_workers'] = 8\n",
    "\n",
    "# ===============\n",
    "# Manager - Train\n",
    "# ===============\n",
    "TRAIN_COMMON_PARAMS['manager.train_params'] = {\n",
    "    'device': 'cuda', \n",
    "    'num_epochs': 5,\n",
    "    'virtual_batch_size': 1,  # number of batches in one virtual batch\n",
    "    'start_saving_epochs': 10,  # first epoch to start saving checkpoints from\n",
    "    'gap_between_saving_epochs': 5,  # number of epochs between saved checkpoint\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.best_epoch_source'] = {\n",
    "    'source': 'metrics.accuracy',  # can be any key from 'epoch_results'\n",
    "    'optimization': 'max',  # can be either min/max\n",
    "    'on_equal_values': 'better',\n",
    "    # can be either better/worse - whether to consider best epoch when values are equal\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.learning_rate'] = 1e-4\n",
    "TRAIN_COMMON_PARAMS['manager.weight_decay'] = 0.001\n",
    "TRAIN_COMMON_PARAMS['manager.resume_checkpoint_filename'] = None  # if not None, will try to load the checkpoint\n",
    "\n",
    "train_params = TRAIN_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Helper function**\n",
    "TOOD: elaborate? delete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_softmax(output):\n",
    "    if isinstance(output, torch.Tensor):  # validation\n",
    "        logits = output\n",
    "    else:  # train\n",
    "        logits = output.logits\n",
    "    cls_preds = F.softmax(logits, dim=1)\n",
    "    return logits, cls_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set logger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFuse Train\u001b[0m\n",
      "\u001b[35mmodel_dir=fuse_examples/mnist/model_dir\u001b[0m\n",
      "\u001b[35mcache_dir=fuse_examples/mnist/cache_dir\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fuse_logger_start(output_path=paths['model_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Train', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'model_dir={paths[\"model_dir\"]}', {'color': 'magenta'})\n",
    "lgr.info(f'cache_dir={paths[\"cache_dir\"]}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define the logger**\n",
    "TODO: elaborate, what is the use of it? common options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFuse Train\u001b[0m\n",
      "\u001b[35mmodel_dir=fuse_examples/mnist/model_dir\u001b[0m\n",
      "\u001b[35mcache_dir=fuse_examples/mnist/cache_dir\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fuse_logger_start(output_path=paths['model_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Train', {'attrs': ['bold', 'underline']})\n",
    "\n",
    "lgr.info(f'model_dir={paths[\"model_dir\"]}', {'color': 'magenta'})\n",
    "lgr.info(f'cache_dir={paths[\"cache_dir\"]}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain Data:\u001b[0m\n",
      "- Create sampler:\n",
      "- Create sampler: Done\n",
      "\u001b[1mTrain Data: Done\u001b[0m\n",
      "\u001b[1mValidation Data:\u001b[0m\n",
      "\u001b[1mValidation Data: Done\u001b[0m\n",
      "\u001b[1mModel:\u001b[0m\n",
      "\u001b[1mModel: Done\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "\u001b[33mKey lr_sch_target not found in config parameter, setting value to default (train.losses.total_loss)\u001b[0m\n",
      "\u001b[1m\u001b[31mTotal number of parameters in model:11,175,370, trainable parameters:11,175,370\u001b[0m\n",
      "Train Dataset Summary:\n",
      "Class = <class 'fuse.data.dataset.dataset_wrapper.FuseDatasetWrapper'>\n",
      "Processors:\n",
      "------------------------\n",
      "<fuse.data.dataset.dataset_wrapper.DatasetProcessor object at 0x7ff06c0c8d10>\n",
      "Cache destination:\n",
      "------------------\n",
      "None\n",
      "Augmentor:\n",
      "----------\n",
      "None\n",
      "Data source:\n",
      "------------\n",
      "FuseDataSourceFromList - 60000 samples\n",
      "\n",
      "Sample keys:\n",
      "------------\n",
      "['data.descriptor', 'data.image', 'data.label']\n",
      "Basic Data Statistic:\n",
      "-------------------\n",
      "\n",
      "Validation Dataset Summary:\n",
      "Class = <class 'fuse.data.dataset.dataset_wrapper.FuseDatasetWrapper'>\n",
      "Processors:\n",
      "------------------------\n",
      "<fuse.data.dataset.dataset_wrapper.DatasetProcessor object at 0x7ff06c588f90>\n",
      "Cache destination:\n",
      "------------------\n",
      "None\n",
      "Augmentor:\n",
      "----------\n",
      "None\n",
      "Data source:\n",
      "------------\n",
      "FuseDataSourceFromList - 10000 samples\n",
      "\n",
      "Sample keys:\n",
      "------------\n",
      "['data.descriptor', 'data.image', 'data.label']\n",
      "Basic Data Statistic:\n",
      "-------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:14<00:00, 23.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Pre-Training:\n",
      "losses.cls_loss      = 2.464972653788721\n",
      "losses.total_loss    = 2.464972653788721\n",
      "metrics.accuracy     = 0.0951\n",
      "Start training on epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2248/2248 [02:48<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:13<00:00, 23.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThis is the best epoch ever (metrics.accuracy = 0.8209)\u001b[0m\n",
      "\u001b[1m\u001b[4mStats for epoch: 1 (Currently the best epoch for source metrics.accuracy!)\u001b[0m\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "|                          | Best Epoch Value         | Current Epoch Validation | Current Epoch Train      |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss          | 0.6196                   | 0.6196                   | 1.0614                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss        | 0.6196                   | 0.6196                   | 1.0614                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy         | 0.8209                   | 0.8209                   | 0.6520                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: fuse_examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 12 minutes, 24 seconds (last epoch time: 3 minutes, 6 seconds)\u001b[0m\n",
      "Start training on epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2248/2248 [02:48<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:14<00:00, 23.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThis is the best epoch ever (metrics.accuracy = 0.845)\u001b[0m\n",
      "\u001b[1m\u001b[4mStats for epoch: 2 (Currently the best epoch for source metrics.accuracy!)\u001b[0m\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "|                          | Best Epoch Value         | Current Epoch Validation | Current Epoch Train      |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss          | 0.5730                   | 0.5730                   | 0.8927                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss        | 0.5730                   | 0.5730                   | 0.8927                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy         | 0.8450                   | 0.8450                   | 0.7079                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: fuse_examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 9 minutes, 20 seconds (last epoch time: 3 minutes, 6 seconds)\u001b[0m\n",
      "Start training on epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2248/2248 [02:49<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:14<00:00, 23.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThis is the best epoch ever (metrics.accuracy = 0.8553)\u001b[0m\n",
      "\u001b[1m\u001b[4mStats for epoch: 3 (Currently the best epoch for source metrics.accuracy!)\u001b[0m\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "|                          | Best Epoch Value         | Current Epoch Validation | Current Epoch Train      |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss          | 0.5509                   | 0.5509                   | 0.9024                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss        | 0.5509                   | 0.5509                   | 0.9024                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy         | 0.8553                   | 0.8553                   | 0.7050                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: fuse_examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 6 minutes, 15 seconds (last epoch time: 3 minutes, 7 seconds)\u001b[0m\n",
      "Start training on epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2248/2248 [02:50<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:14<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for epoch: 4 (Best epoch is 3 for source metrics.accuracy)\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "|                          | Best Epoch Value         | Current Epoch Validation | Current Epoch Train      |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss          | 0.5509                   | 0.5529                   | 0.8478                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss        | 0.5509                   | 0.5529                   | 0.8478                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy         | 0.8553                   | 0.8398                   | 0.7307                   |\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: fuse_examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 3 minutes, 8 seconds (last epoch time: 3 minutes, 8 seconds)\u001b[0m\n",
      "\u001b[1mTrain: Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Data\n",
    "# ==============================================================================\n",
    "# Train Data\n",
    "lgr.info(f'Train Data:', {'attrs': 'bold'})\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# Create dataset\n",
    "torch_train_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=True, transform=transform)\n",
    "# wrapping torch dataset\n",
    "# FIXME: support also using torch dataset directly\n",
    "train_dataset = FuseDatasetWrapper(name='train', dataset=torch_train_dataset, mapping=('image', 'label'))\n",
    "train_dataset.create()\n",
    "lgr.info(f'- Create sampler:')\n",
    "sampler = FuseSamplerBalancedBatch(dataset=train_dataset,\n",
    "                                balanced_class_name='data.label',\n",
    "                                num_balanced_classes=10,\n",
    "                                batch_size=train_params['data.batch_size'],\n",
    "                                balanced_class_weights=None)\n",
    "lgr.info(f'- Create sampler: Done')\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=train_params['data.train_num_workers'])\n",
    "lgr.info(f'Train Data: Done', {'attrs': 'bold'})\n",
    "\n",
    "## Validation data\n",
    "lgr.info(f'Validation Data:', {'attrs': 'bold'})\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=train_params['data.batch_size'],\n",
    "                                num_workers=train_params['data.validation_num_workers'])\n",
    "lgr.info(f'Validation Data: Done', {'attrs': 'bold'})\n",
    "\n",
    "# ==============================================================================\n",
    "# Model\n",
    "# ==============================================================================\n",
    "lgr.info('Model:', {'attrs': 'bold'})\n",
    "\n",
    "torch_model = models.resnet18(num_classes=10)\n",
    "# modify conv1 to support single channel image\n",
    "torch_model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# use adaptive avg pooling to support mnist low resolution images\n",
    "torch_model.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "model = FuseModelWrapper(model=torch_model,\n",
    "                        model_inputs=['data.image'],\n",
    "                        post_forward_processing_function=perform_softmax,\n",
    "                        model_outputs=['logits.classification', 'output.classification']\n",
    "                        )\n",
    "\n",
    "lgr.info('Model: Done', {'attrs': 'bold'})\n",
    "\n",
    "# ====================================================================================\n",
    "#  Loss\n",
    "# ====================================================================================\n",
    "losses = {\n",
    "    'cls_loss': FuseLossDefault(pred_name='model.logits.classification', target_name='data.label', callable=F.cross_entropy, weight=1.0),\n",
    "}\n",
    "\n",
    "# ====================================================================================\n",
    "# Metrics\n",
    "# ====================================================================================\n",
    "metrics = {\n",
    "    'accuracy': FuseMetricAccuracy(pred_name='model.output.classification', target_name='data.label')\n",
    "}\n",
    "\n",
    "# =====================================================================================\n",
    "#  Callbacks\n",
    "# =====================================================================================\n",
    "callbacks = [\n",
    "    # default callbacks\n",
    "    FuseTensorboardCallback(model_dir=paths['model_dir']),  # save statistics for tensorboard\n",
    "    FuseMetricStatisticsCallback(output_path=paths['model_dir'] + \"/metrics.csv\"),  # save statistics a csv file\n",
    "    FuseTimeStatisticsCallback(num_epochs=train_params['manager.train_params']['num_epochs'], load_expected_part=0.1)  # time profiler\n",
    "]\n",
    "\n",
    "# =====================================================================================\n",
    "#  Manager - Train\n",
    "# =====================================================================================\n",
    "lgr.info('Train:', {'attrs': 'bold'})\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_params['manager.learning_rate'], weight_decay=train_params['manager.weight_decay'])\n",
    "\n",
    "# create learning scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# train from scratch\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "# Providing the objects required for the training process.\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_params['manager.train_params'])\n",
    "\n",
    "## Continue training\n",
    "if train_params['manager.resume_checkpoint_filename'] is not None:\n",
    "    # Loading the checkpoint including model weights, learning rate, and epoch_index.\n",
    "    manager.load_checkpoint(checkpoint=train_params['manager.resume_checkpoint_filename'], mode='train')\n",
    "\n",
    "# Start training\n",
    "manager.train(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader)\n",
    "\n",
    "lgr.info('Train: Done', {'attrs': 'bold'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Infer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_COMMON_PARAMS = {}\n",
    "INFER_COMMON_PARAMS['infer_filename'] = 'validation_set_infer.gz'\n",
    "INFER_COMMON_PARAMS['checkpoint'] = 'best'  # Fuse TIP: possible values are 'best', 'last' or epoch_index.\n",
    "\n",
    "infer_common_params = INFER_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define logger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFuse Inference\u001b[0m\n",
      "\u001b[35minfer_filename=fuse_examples/mnist/infer_dir/validation_set_infer.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fuse_logger_start(output_path=paths['inference_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Inference', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'infer_filename={os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"])}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: fuse_examples/mnist/model_dir\n",
      "\u001b[33mLoading checkpoint file: fuse_examples/mnist/model_dir/checkpoint_best_0_epoch.pth. values_to_resume all\u001b[0m\n",
      "\u001b[33mKey device not found in config parameter, setting value to default (cuda)\u001b[0m\n",
      "\u001b[33mKey virtual_batch_size not found in config parameter, setting value to default (1)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:01<00:00, 81.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save inference results into fuse_examples/mnist/infer_dir/validation_set_infer.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descriptor</th>\n",
       "      <th>model.output.classification</th>\n",
       "      <th>data.label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(validation, 0)</td>\n",
       "      <td>[0.0016879884, 0.0015029196, 0.0051113814, 0.0...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(validation, 1)</td>\n",
       "      <td>[0.048130117, 0.024796639, 0.58028364, 0.14518...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(validation, 2)</td>\n",
       "      <td>[0.0019267538, 0.981097, 0.00044614665, 0.0015...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(validation, 3)</td>\n",
       "      <td>[0.99099356, 0.00012841726, 0.00017717913, 1.5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(validation, 4)</td>\n",
       "      <td>[0.052714493, 0.026158107, 0.021874268, 0.0045...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>(validation, 9995)</td>\n",
       "      <td>[0.00034772445, 0.0002892727, 0.9494368, 0.010...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>(validation, 9996)</td>\n",
       "      <td>[0.054082025, 0.012338727, 0.115864225, 0.6180...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>(validation, 9997)</td>\n",
       "      <td>[0.00045667685, 0.010034586, 0.0019736052, 0.0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>(validation, 9998)</td>\n",
       "      <td>[0.010676819, 0.033213064, 0.0027186736, 0.005...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>(validation, 9999)</td>\n",
       "      <td>[0.16548231, 0.0022004468, 0.028541315, 0.0008...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              descriptor                        model.output.classification  \\\n",
       "0        (validation, 0)  [0.0016879884, 0.0015029196, 0.0051113814, 0.0...   \n",
       "1        (validation, 1)  [0.048130117, 0.024796639, 0.58028364, 0.14518...   \n",
       "2        (validation, 2)  [0.0019267538, 0.981097, 0.00044614665, 0.0015...   \n",
       "3        (validation, 3)  [0.99099356, 0.00012841726, 0.00017717913, 1.5...   \n",
       "4        (validation, 4)  [0.052714493, 0.026158107, 0.021874268, 0.0045...   \n",
       "...                  ...                                                ...   \n",
       "9995  (validation, 9995)  [0.00034772445, 0.0002892727, 0.9494368, 0.010...   \n",
       "9996  (validation, 9996)  [0.054082025, 0.012338727, 0.115864225, 0.6180...   \n",
       "9997  (validation, 9997)  [0.00045667685, 0.010034586, 0.0019736052, 0.0...   \n",
       "9998  (validation, 9998)  [0.010676819, 0.033213064, 0.0027186736, 0.005...   \n",
       "9999  (validation, 9999)  [0.16548231, 0.0022004468, 0.028541315, 0.0008...   \n",
       "\n",
       "      data.label  \n",
       "0              7  \n",
       "1              2  \n",
       "2              1  \n",
       "3              0  \n",
       "4              4  \n",
       "...          ...  \n",
       "9995           2  \n",
       "9996           3  \n",
       "9997           4  \n",
       "9998           5  \n",
       "9999           6  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, collate_fn=validation_dataset.collate_fn, batch_size=2, num_workers=2)\n",
    "\n",
    "## Manager for inference\n",
    "manager = FuseManagerDefault()\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analyze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Analyze Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYZE_COMMON_PARAMS = {}\n",
    "ANALYZE_COMMON_PARAMS['infer_filename'] = INFER_COMMON_PARAMS['infer_filename']\n",
    "ANALYZE_COMMON_PARAMS['output_filename'] = os.path.join(PATHS['analyze_dir'], 'all_metrics')\n",
    "\n",
    "analyze_common_params = ANALYZE_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define logger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFuse Analyze\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fuse_logger_start(output_path=None, console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Analyze', {'attrs': ['bold', 'underline']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 5117.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mResults\u001b[0m\n",
      "\u001b[1m\n",
      "Metric accuracy:\u001b[0m\n",
      "0.8553\n",
      "\u001b[1m\n",
      "Metric roc:\u001b[0m\n",
      "\u001b[1m\n",
      "Metric auc:\u001b[0m\n",
      "class_0: 0.9964835512919138\n",
      "class_1: 0.9974063224431078\n",
      "class_2: 0.9866720345898249\n",
      "class_3: 0.9845814381215652\n",
      "class_4: 0.9909174635567064\n",
      "class_5: 0.9815306752453372\n",
      "class_6: 0.987555407172005\n",
      "class_7: 0.9798445574732284\n",
      "class_8: 0.9744527672964846\n",
      "class_9: 0.979112908746209\n",
      "macro_avg: 0.9858557125936382\n",
      "\u001b[1m\u001b[35m\n",
      "Analyzer done. Results saved in fuse_examples/mnist/analyze_dir/all_metrics  \u001b[0m\n",
      "\u001b[1m\u001b[35m\n",
      "Analyzer done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# metrics\n",
    "metrics = {\n",
    "    'accuracy': FuseMetricAccuracy(pred_name='model.output.classification', target_name='data.label'),\n",
    "    'roc': FuseMetricROCCurve(pred_name='model.output.classification', target_name='data.label', output_filename=os.path.join(paths['inference_dir'], 'roc_curve.png')),\n",
    "    'auc': FuseMetricAUC(pred_name='model.output.classification', target_name='data.label')\n",
    "}\n",
    "\n",
    "# create analyzer\n",
    "analyzer = FuseAnalyzerDefault()\n",
    "\n",
    "# run\n",
    "# FIXME: simplify analyze interface for this case\n",
    "results = analyzer.analyze(gt_processors={},\n",
    "                data_pickle_filename=os.path.join(paths[\"inference_dir\"], analyze_common_params[\"infer_filename\"]),\n",
    "                metrics=metrics,\n",
    "                output_filename=analyze_common_params['output_filename'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598f6cce495816406fbd34fea65bf7c807885b1496bf9be8c5dc5b47eac7d159"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38_tf2.3_pytorch1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
