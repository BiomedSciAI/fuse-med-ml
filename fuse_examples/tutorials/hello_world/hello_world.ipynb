{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## Installation Details - Google Colab\n",
    "\n",
    "### **Enable GPU Support**\n",
    "\n",
    "To use GPU through Google Colab, change the runtime mode to GPU:\n",
    "\n",
    "From the \"Runtime\" menu select \"Change Runtime Type\", choose \"GPU\" from the drop-down menu and click \"SAVE\"\n",
    "When asked, reboot the system.\n",
    "\n",
    "### **Install FuseMedML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/fuse-med-ml.git\n",
    "%cd fuse-med-ml\n",
    "# !pip install -e .\n",
    "%cd fuse_examples/tutorials/multimodality_image_clinical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################\n",
    "# Fuse\n",
    "###########################################################################################################\n",
    "##########################################\n",
    "# Debug modes\n",
    "##########################################\n",
    "mode = 'default'  # Options: 'default', 'fast', 'debug', 'verbose', 'user'. See details in FuseUtilsDebug\n",
    "debug = FuseUtilsDebug(mode)\n",
    "\n",
    "##########################################\n",
    "# Output Paths\n",
    "##########################################\n",
    "ROOT = 'examples' # TODO: fill path here\n",
    "PATHS = {'model_dir': os.path.join(ROOT, 'mnist/model_dir'),\n",
    "         'force_reset_model_dir': True,  # If True will reset model dir automatically - otherwise will prompt 'are you sure' message.\n",
    "         'cache_dir': os.path.join(ROOT, 'mnist/cache_dir'),\n",
    "         'inference_dir': os.path.join(ROOT, 'mnist/infer_dir'),\n",
    "         'analyze_dir': os.path.join(ROOT, 'mnist/analyze_dir')}\n",
    "\n",
    "##########################################\n",
    "# Train Common Params\n",
    "##########################################\n",
    "# ============\n",
    "# Data\n",
    "# ============\n",
    "TRAIN_COMMON_PARAMS = {}\n",
    "TRAIN_COMMON_PARAMS['data.batch_size'] = 30\n",
    "TRAIN_COMMON_PARAMS['data.train_num_workers'] = 8\n",
    "TRAIN_COMMON_PARAMS['data.validation_num_workers'] = 8\n",
    "\n",
    "# ===============\n",
    "# Manager - Train\n",
    "# ===============\n",
    "TRAIN_COMMON_PARAMS['manager.train_params'] = {\n",
    "    'device': 'cuda', \n",
    "    'num_epochs': 5,\n",
    "    'virtual_batch_size': 1,  # number of batches in one virtual batch\n",
    "    'start_saving_epochs': 10,  # first epoch to start saving checkpoints from\n",
    "    'gap_between_saving_epochs': 5,  # number of epochs between saved checkpoint\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.best_epoch_source'] = {\n",
    "    'source': 'metrics.accuracy',  # can be any key from 'epoch_results'\n",
    "    'optimization': 'max',  # can be either min/max\n",
    "    'on_equal_values': 'better',\n",
    "    # can be either better/worse - whether to consider best epoch when values are equal\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.learning_rate'] = 1e-4\n",
    "TRAIN_COMMON_PARAMS['manager.weight_decay'] = 0.001\n",
    "TRAIN_COMMON_PARAMS['manager.resume_checkpoint_filename'] = None  # if not None, will try to load the checkpoint\n",
    "\n",
    "\n",
    "def perform_softmax(output):\n",
    "    if isinstance(output, torch.Tensor):  # validation\n",
    "        logits = output\n",
    "    else:  # train\n",
    "        logits = output.logits\n",
    "    cls_preds = F.softmax(logits, dim=1)\n",
    "    return logits, cls_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set logger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_logger_start(output_path=paths['model_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Train', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'model_dir={paths[\"model_dir\"]}', {'color': 'magenta'})\n",
    "lgr.info(f'cache_dir={paths[\"cache_dir\"]}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Logger\n",
    "# ==============================================================================\n",
    "fuse_logger_start(output_path=paths['model_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Train', {'attrs': ['bold', 'underline']})\n",
    "\n",
    "lgr.info(f'model_dir={paths[\"model_dir\"]}', {'color': 'magenta'})\n",
    "lgr.info(f'cache_dir={paths[\"cache_dir\"]}', {'color': 'magenta'})\n",
    "\n",
    "# ==============================================================================\n",
    "# Data\n",
    "# ==============================================================================\n",
    "# Train Data\n",
    "lgr.info(f'Train Data:', {'attrs': 'bold'})\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# Create dataset\n",
    "torch_train_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=True, transform=transform)\n",
    "# wrapping torch dataset\n",
    "# FIXME: support also using torch dataset directly\n",
    "train_dataset = FuseDatasetWrapper(name='train', dataset=torch_train_dataset, mapping=('image', 'label'))\n",
    "train_dataset.create()\n",
    "lgr.info(f'- Create sampler:')\n",
    "sampler = FuseSamplerBalancedBatch(dataset=train_dataset,\n",
    "                                balanced_class_name='data.label',\n",
    "                                num_balanced_classes=10,\n",
    "                                batch_size=train_params['data.batch_size'],\n",
    "                                balanced_class_weights=None)\n",
    "lgr.info(f'- Create sampler: Done')\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=train_params['data.train_num_workers'])\n",
    "lgr.info(f'Train Data: Done', {'attrs': 'bold'})\n",
    "\n",
    "## Validation data\n",
    "lgr.info(f'Validation Data:', {'attrs': 'bold'})\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=train_params['data.batch_size'],\n",
    "                                num_workers=train_params['data.validation_num_workers'])\n",
    "lgr.info(f'Validation Data: Done', {'attrs': 'bold'})\n",
    "\n",
    "# ==============================================================================\n",
    "# Model\n",
    "# ==============================================================================\n",
    "lgr.info('Model:', {'attrs': 'bold'})\n",
    "\n",
    "torch_model = models.resnet18(num_classes=10)\n",
    "# modify conv1 to support single channel image\n",
    "torch_model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# use adaptive avg pooling to support mnist low resolution images\n",
    "torch_model.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "model = FuseModelWrapper(model=torch_model,\n",
    "                        model_inputs=['data.image'],\n",
    "                        post_forward_processing_function=perform_softmax,\n",
    "                        model_outputs=['logits.classification', 'output.classification']\n",
    "                        )\n",
    "\n",
    "lgr.info('Model: Done', {'attrs': 'bold'})\n",
    "\n",
    "# ====================================================================================\n",
    "#  Loss\n",
    "# ====================================================================================\n",
    "losses = {\n",
    "    'cls_loss': FuseLossDefault(pred_name='model.logits.classification', target_name='data.label', callable=F.cross_entropy, weight=1.0),\n",
    "}\n",
    "\n",
    "# ====================================================================================\n",
    "# Metrics\n",
    "# ====================================================================================\n",
    "metrics = {\n",
    "    'accuracy': FuseMetricAccuracy(pred_name='model.output.classification', target_name='data.label')\n",
    "}\n",
    "\n",
    "# =====================================================================================\n",
    "#  Callbacks\n",
    "# =====================================================================================\n",
    "callbacks = [\n",
    "    # default callbacks\n",
    "    FuseTensorboardCallback(model_dir=paths['model_dir']),  # save statistics for tensorboard\n",
    "    FuseMetricStatisticsCallback(output_path=paths['model_dir'] + \"/metrics.csv\"),  # save statistics a csv file\n",
    "    FuseTimeStatisticsCallback(num_epochs=train_params['manager.train_params']['num_epochs'], load_expected_part=0.1)  # time profiler\n",
    "]\n",
    "\n",
    "# =====================================================================================\n",
    "#  Manager - Train\n",
    "# =====================================================================================\n",
    "lgr.info('Train:', {'attrs': 'bold'})\n",
    "\n",
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_params['manager.learning_rate'], weight_decay=train_params['manager.weight_decay'])\n",
    "\n",
    "# create learning scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# train from scratch\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "# Providing the objects required for the training process.\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_params['manager.train_params'])\n",
    "\n",
    "## Continue training\n",
    "if train_params['manager.resume_checkpoint_filename'] is not None:\n",
    "    # Loading the checkpoint including model weights, learning rate, and epoch_index.\n",
    "    manager.load_checkpoint(checkpoint=train_params['manager.resume_checkpoint_filename'], mode='train')\n",
    "\n",
    "# Start training\n",
    "manager.train(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader)\n",
    "\n",
    "lgr.info('Train: Done', {'attrs': 'bold'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Infer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Inference Common Params\n",
    "######################################\n",
    "INFER_COMMON_PARAMS = {}\n",
    "INFER_COMMON_PARAMS['infer_filename'] = 'validation_set_infer.gz'\n",
    "INFER_COMMON_PARAMS['checkpoint'] = 'best'  # Fuse TIP: possible values are 'best', 'last' or epoch_index.\n",
    "\n",
    "\n",
    "# ---\n",
    "#### Logger\n",
    "fuse_logger_start(output_path=paths['inference_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Inference', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'infer_filename={os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"])}', {'color': 'magenta'})\n",
    "\n",
    "## Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, collate_fn=validation_dataset.collate_fn, batch_size=2, num_workers=2)\n",
    "\n",
    "## Manager for inference\n",
    "manager = FuseManagerDefault()\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_logger_start(output_path=None, console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Analyze', {'attrs': ['bold', 'underline']})\n",
    "\n",
    "# metrics\n",
    "metrics = {\n",
    "    'accuracy': FuseMetricAccuracy(pred_name='model.output.classification', target_name='data.label'),\n",
    "    'roc': FuseMetricROCCurve(pred_name='model.output.classification', target_name='data.label', output_filename=os.path.join(paths['inference_dir'], 'roc_curve.png')),\n",
    "    'auc': FuseMetricAUC(pred_name='model.output.classification', target_name='data.label')\n",
    "}\n",
    "\n",
    "# create analyzer\n",
    "analyzer = FuseAnalyzerDefault()\n",
    "\n",
    "# run\n",
    "# FIXME: simplify analyze interface for this case\n",
    "results = analyzer.analyze(gt_processors={},\n",
    "                data_pickle_filename=os.path.join(paths[\"inference_dir\"], analyze_common_params[\"infer_filename\"]),\n",
    "                metrics=metrics,\n",
    "                output_filename=analyze_common_params['output_filename'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
