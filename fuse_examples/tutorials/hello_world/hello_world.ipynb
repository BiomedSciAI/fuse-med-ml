{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FuseMedML - Hello world\n",
    "Welcome!\\\n",
    "In this tutorial we'll cover the basics in our FuseMedML open soruce library through an hands-on notebook.\\\n",
    "\n",
    "Goals:\n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## FuseMedML\n",
    "[![Github repo](https://img.shields.io/static/v1?label=GitHub&message=FuseMedML&color=brightgreen)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/fuse-med-ml.svg)](https://badge.fury.io/py/fuse-med-ml)\n",
    "\n",
    "[![Slack channel](https://img.shields.io/badge/support-slack-slack.svg?logo=slack)](https://join.slack.com/t/fusemedml/shared_invite/zt-xr1jaj29-h7IMsSc0Lq4qpVNxW97Phw)\n",
    "\n",
    "[![Open Source](https://badges.frapsoft.com/os/v1/open-source.svg)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "\n",
    "FuseMedML is an open-source python-based framework designed to enhance collaboration and accelerate discoveries in Fused Medical data through advanced Machine Learning technologies. \n",
    "\n",
    "Initial version is PyTorch-based and focuses on deep learning on medical imaging.\n",
    "\n",
    "\n",
    "## **FuseMedML Key Concepts in a Nutshell**\n",
    "### Share and Reuse\n",
    "\n",
    "A common generic implementation, you can reuse, is provided for most components in the pipeline. \n",
    "\n",
    "The naming convention for the common implementation is `Fuse***Default` \n",
    "\n",
    "FuseMedML comes with a large collection of components that grow with each new project. Some of them are entirely generic and the others are domain specific.\n",
    "\n",
    "\n",
    "Don't forget to **contribute** back and **share** them. \n",
    "\n",
    "### Decoupling\n",
    "The decoupling is achieved by the fact that, in most cases, the objects do not interact directly. Instead, the information and data are routed between components using *namespaces* (examples below). \n",
    "\n",
    "Meaning, each object extracts its input from and saves its output into a dictionary named `batch_dict`. \n",
    "\n",
    "`batch_dict` aggregates the outputs of all the objects through a single batch. \n",
    "\n",
    "<br />\n",
    "\n",
    "**Example of the decoupling approach:**\n",
    "```python\n",
    "FuseMetricAUC(pred_name='model.output.classification', target_name='data.gt.classification')  \n",
    "```\n",
    "\n",
    "`FuseMetricAUC` will read the required tensors to compute AUC from `batch_dict`. The relevant dictionary keys are `pred_name` and `target_name`. \n",
    "\n",
    "This approach allows writing a generic metric which is completely independent of the model and data extractor. \n",
    "\n",
    "In addition, it allows to easily re-use this object in a plug & play manner without adding extra code. \n",
    "\n",
    "Such an approach also allows us to use it several times in case we have multiple heads/tasks.\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "When a batch is completed, only the required key-value pairs from `batch_dict`, such as the loss values, will be collected in another dictionary named `epoch_results`. \n",
    "\n",
    "Both `batch_dict` and `epoch_results` are nested dictionaries. To easily access the data stored in those dictionaries, use `FuseUtilsHierarchicalDict`:\n",
    "\n",
    "```python\n",
    "FuseUtilsHierarchicalDict.get(batch_dict, ‘model.output.classification’)\n",
    "``` \n",
    "\n",
    "will return `batch_dict[‘model’][‘output’][‘classification’]`\n",
    "\n",
    "### Manager API\n",
    "The manager is the main API while using Fuse - it resposible for the Train and Infer functionallity.\n",
    "\n",
    "Possible workflows are listed in the FuseMangerDefault's documentation. Here are two examples:\n",
    "\n",
    "##### **Train: Init -> set objects -> train**\n",
    "```python\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_common_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_common_params['manager.train_params'],\n",
    "                    output_model_dir=paths['model_dir'])\n",
    "\n",
    "manager.train(train_dataloader=train_dataloader,\n",
    "                validation_dataloader=validation_dataloader)\n",
    "```\n",
    "\n",
    "##### **Infer: Init -> infer**\n",
    "```python\n",
    "manager = FuseManagerDefault()\n",
    "\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Use PyTorch directly and alternative frameworks\n",
    "\n",
    "FuseMedML uses and extends PyTorch only when required by the user. \n",
    "You can mix FuseMedML with PyTorch code, components from alternative frameworks and other popular GitHub projects. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## **Installation Details - Google Colab**\n",
    "\n",
    "#### **Enable GPU Support**\n",
    "\n",
    "To use GPU through Google Colab, change the runtime mode to GPU:\n",
    "\n",
    "From the \"Runtime\" menu select \"Change Runtime Type\", choose \"GPU\" from the drop-down menu and click \"SAVE\"\n",
    "When asked, reboot the system.\n",
    "\n",
    "#### **Install FuseMedML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/fuse-med-ml.git\n",
    "# %cd fuse-med-ml\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from fuse.analyzer.analyzer_default import FuseAnalyzerDefault\n",
    "from fuse.data.dataset.dataset_wrapper import FuseDatasetWrapper\n",
    "from fuse.data.sampler.sampler_balanced_batch import FuseSamplerBalancedBatch\n",
    "from fuse.losses.loss_default import FuseLossDefault\n",
    "from fuse.managers.callbacks.callback_metric_statistics import FuseMetricStatisticsCallback\n",
    "from fuse.managers.callbacks.callback_tensorboard import FuseTensorboardCallback\n",
    "from fuse.managers.callbacks.callback_time_statistics import FuseTimeStatisticsCallback\n",
    "from fuse.managers.manager_default import FuseManagerDefault\n",
    "from fuse.metrics.classification.metric_accuracy import FuseMetricAccuracy\n",
    "from fuse.metrics.classification.metric_auc import FuseMetricAUC\n",
    "from fuse.metrics.classification.metric_roc_curve import FuseMetricROCCurve\n",
    "from fuse.models.model_wrapper import FuseModelWrapper\n",
    "from fuse.utils.utils_gpu import FuseUtilsGPU\n",
    "from fuse.utils.utils_debug import FuseUtilsDebug\n",
    "from fuse.utils.utils_logger import fuse_logger_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Setup debugger**\n",
    "The supported modes are: 'default', 'fast', 'debug', 'verbose', 'user'.\n",
    "\n",
    "More details in FuseUtilsDebug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'default'\n",
    "debug = FuseUtilsDebug(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Output paths**\n",
    "The user is able to customize the output directory by changing ROOT as following below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'examples' # TODO: fill path here\n",
    "PATHS = {'model_dir': os.path.join(ROOT, 'mnist/model_dir'),\n",
    "         'force_reset_model_dir': True,  # If True will reset model dir automatically - otherwise will prompt 'are you sure' message.\n",
    "         'cache_dir': os.path.join(ROOT, 'mnist/cache_dir'),\n",
    "         'inference_dir': os.path.join(ROOT, 'mnist/infer_dir'),\n",
    "         'analyze_dir': os.path.join(ROOT, 'mnist/analyze_dir')}\n",
    "\n",
    "paths = PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training Parameters**\n",
    "* Data - define parameters for the preproccesing.\n",
    "* Manager - define parameters using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COMMON_PARAMS = {}\n",
    "TRAIN_COMMON_PARAMS['data.batch_size'] = 30\n",
    "TRAIN_COMMON_PARAMS['data.train_num_workers'] = 8\n",
    "TRAIN_COMMON_PARAMS['data.validation_num_workers'] = 8\n",
    "\n",
    "TRAIN_COMMON_PARAMS['manager.train_params'] = {\n",
    "    'device': 'cuda', \n",
    "    'num_epochs': 5,\n",
    "    'virtual_batch_size': 1,  # number of batches in one virtual batch\n",
    "    'start_saving_epochs': 10,  # first epoch to start saving checkpoints from\n",
    "    'gap_between_saving_epochs': 5,  # number of epochs between saved checkpoint\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.best_epoch_source'] = {\n",
    "    'source': 'metrics.accuracy',  # can be any key from 'epoch_results'\n",
    "    'optimization': 'max',  # can be either min/max\n",
    "    'on_equal_values': 'better',\n",
    "    # can be either better/worse - whether to consider best epoch when values are equal\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.learning_rate'] = 1e-4\n",
    "TRAIN_COMMON_PARAMS['manager.weight_decay'] = 0.001\n",
    "TRAIN_COMMON_PARAMS['manager.resume_checkpoint_filename'] = None  # if not None, will try to load the checkpoint\n",
    "\n",
    "train_params = TRAIN_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Allocate GPUs**\n",
    "Look for a free GPUs and allocate accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use cpu - set NUM_GPUS to 0\n",
    "NUM_GPUS = 0\n",
    "if NUM_GPUS == 0:\n",
    "    TRAIN_COMMON_PARAMS['manager.train_params']['device'] = 'cpu' \n",
    "# uncomment if you want to use specific gpus instead of automatically looking for free ones\n",
    "force_gpus = None  # [0]\n",
    "FuseUtilsGPU.choose_and_enable_multiple_gpus(NUM_GPUS, force_gpus=force_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_softmax(output):\n",
    "    if isinstance(output, torch.Tensor):  # validation\n",
    "        logits = output\n",
    "    else:  # train\n",
    "        logits = output.logits\n",
    "    cls_preds = F.softmax(logits, dim=1)\n",
    "    return logits, cls_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Init logger**\n",
    "The logger does two things:\n",
    "- Output log automatically to three destinations:\n",
    "    1. Console\n",
    "    2. File - a copy of the console.\n",
    "    3. Verboes file - used for debug.\n",
    "\n",
    "<p></p>\n",
    "\n",
    "- Save a copy of the template file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_logger_start(output_path=paths['model_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Train', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'model_dir={paths[\"model_dir\"]}', {'color': 'magenta'})\n",
    "lgr.info(f'cache_dir={paths[\"cache_dir\"]}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "lgr.info(f'Train Data:', {'attrs': 'bold'})\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# Create dataset\n",
    "torch_train_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=True, transform=transform)\n",
    "# wrapping torch dataset\n",
    "# FIXME: support also using torch dataset directly\n",
    "train_dataset = FuseDatasetWrapper(name='train', dataset=torch_train_dataset, mapping=('image', 'label'))\n",
    "train_dataset.create()\n",
    "lgr.info(f'- Create sampler:')\n",
    "sampler = FuseSamplerBalancedBatch(dataset=train_dataset,\n",
    "                                balanced_class_name='data.label',\n",
    "                                num_balanced_classes=10,\n",
    "                                batch_size=train_params['data.batch_size'],\n",
    "                                balanced_class_weights=None)\n",
    "lgr.info(f'- Create sampler: Done')\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=train_params['data.train_num_workers'])\n",
    "lgr.info(f'Train Data: Done', {'attrs': 'bold'})\n",
    "\n",
    "## Validation data\n",
    "lgr.info(f'Validation Data:', {'attrs': 'bold'})\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=train_params['data.batch_size'],\n",
    "                                num_workers=train_params['data.validation_num_workers'])\n",
    "lgr.info(f'Validation Data: Done', {'attrs': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**\n",
    "Building the model using PyTorch's API and then wrapping it with ours. \n",
    "\n",
    "The model outputs will be aggregated in batch_dict['model.*'].\n",
    "\n",
    "\n",
    "Another option to implement a model is to use o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr.info('Model:', {'attrs': 'bold'})\n",
    "\n",
    "torch_model = models.resnet18(num_classes=10)\n",
    "# modify conv1 to support single channel image\n",
    "torch_model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "# use adaptive avg pooling to support mnist low resolution images\n",
    "torch_model.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "model = FuseModelWrapper(model=torch_model,\n",
    "                        model_inputs=['data.image'],\n",
    "                        post_forward_processing_function=perform_softmax,\n",
    "                        model_outputs=['logits.classification', 'output.classification']\n",
    "                        )\n",
    "\n",
    "lgr.info('Model: Done', {'attrs': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loss function**\n",
    "Dictionary of loss elements. each element is a sub-class of FuseLossBase.\n",
    "\n",
    "The total loss will be the weighted sum of all the elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    'cls_loss': FuseLossDefault(pred_name='model.logits.classification', target_name='data.label', callable=F.cross_entropy, weight=1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Metrics**\n",
    "Dictionary of metric elements. Each element is a sub-class of FuseMetricBase.\n",
    "\n",
    "The metrics will be calculated per epoch for both the validation and train.\n",
    "\n",
    "The 'best_epoch_source', used to save the best model could be based on one of these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': FuseMetricAccuracy(pred_name='model.output.classification', target_name='data.label')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Callbacks**\n",
    "Callbacks are sub-classes of FuseCallbackBase.\n",
    "\n",
    "A callback is an object that can preform actions at various stages of training.\n",
    "\n",
    "In each stage it allows to manipulate either the data, batch_dict or epoch_results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # default callbacks\n",
    "    FuseTensorboardCallback(model_dir=paths['model_dir']),  # save statistics for tensorboard\n",
    "    FuseMetricStatisticsCallback(output_path=paths['model_dir'] + \"/metrics.csv\"),  # save statistics a csv file\n",
    "    FuseTimeStatisticsCallback(num_epochs=train_params['manager.train_params']['num_epochs'], load_expected_part=0.1)  # time profiler\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr.info('Train:', {'attrs': 'bold'})\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_params['manager.learning_rate'], weight_decay=train_params['manager.weight_decay'])\n",
    "\n",
    "# create scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# train from scratch\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "\n",
    "# Providing the objects required for the training process.\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_params['manager.train_params'])\n",
    "\n",
    "## Continue training\n",
    "if train_params['manager.resume_checkpoint_filename'] is not None:\n",
    "    # Loading the checkpoint including model weights, learning rate, and epoch_index.\n",
    "    manager.load_checkpoint(checkpoint=train_params['manager.resume_checkpoint_filename'], mode='train')\n",
    "\n",
    "# Start training\n",
    "manager.train(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader)\n",
    "\n",
    "lgr.info('Train: Done', {'attrs': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Infer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_COMMON_PARAMS = {}\n",
    "INFER_COMMON_PARAMS['infer_filename'] = 'validation_set_infer.gz'\n",
    "INFER_COMMON_PARAMS['checkpoint'] = 'best'  # Fuse TIP: possible values are 'best', 'last' or epoch_index.\n",
    "\n",
    "infer_common_params = INFER_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr.info('Fuse Inference', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'infer_filename={os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"])}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, collate_fn=validation_dataset.collate_fn, batch_size=2, num_workers=2)\n",
    "\n",
    "## Manager for inference\n",
    "manager = FuseManagerDefault()\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analyze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Analyze Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYZE_COMMON_PARAMS = {}\n",
    "ANALYZE_COMMON_PARAMS['infer_filename'] = INFER_COMMON_PARAMS['infer_filename']\n",
    "ANALYZE_COMMON_PARAMS['output_filename'] = os.path.join(PATHS['analyze_dir'], 'all_metrics')\n",
    "analyze_common_params = ANALYZE_COMMON_PARAMS\n",
    "\n",
    "lgr.info('Fuse Analyze', {'attrs': ['bold', 'underline']})\n",
    "\n",
    "# metrics\n",
    "metrics = {\n",
    "    'accuracy': FuseMetricAccuracy(pred_name='model.output.classification', target_name='data.label'),\n",
    "    'roc': FuseMetricROCCurve(pred_name='model.output.classification', target_name='data.label', output_filename=os.path.join(paths['inference_dir'], 'roc_curve.png')),\n",
    "    'auc': FuseMetricAUC(pred_name='model.output.classification', target_name='data.label')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Analyze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create analyzer\n",
    "analyzer = FuseAnalyzerDefault()\n",
    "\n",
    "# run\n",
    "# FIXME: simplify analyze interface for this case\n",
    "results = analyzer.analyze(gt_processors={},\n",
    "                data_pickle_filename=os.path.join(paths[\"inference_dir\"], analyze_common_params[\"infer_filename\"]),\n",
    "                metrics=metrics,\n",
    "                output_filename=analyze_common_params['output_filename'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598f6cce495816406fbd34fea65bf7c807885b1496bf9be8c5dc5b47eac7d159"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38_tf2.3_pytorch1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
