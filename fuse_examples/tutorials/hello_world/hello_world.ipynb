{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FuseMedML - Hello world\n",
    "Welcome!\\\n",
    "In this tutorial we'll cover the basics in our FuseMedML open soruce library through an hands-on notebook.\n",
    "\n",
    "Goals:\n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## FuseMedML\n",
    "[![Github repo](https://img.shields.io/static/v1?label=GitHub&message=FuseMedML&color=brightgreen)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/fuse-med-ml.svg)](https://badge.fury.io/py/fuse-med-ml)\n",
    "\n",
    "[![Slack channel](https://img.shields.io/badge/support-slack-slack.svg?logo=slack)](https://join.slack.com/t/fusemedml/shared_invite/zt-xr1jaj29-h7IMsSc0Lq4qpVNxW97Phw)\n",
    "\n",
    "[![Open Source](https://badges.frapsoft.com/os/v1/open-source.svg)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "\n",
    "FuseMedML is an open-source python-based framework designed to enhance collaboration and accelerate discoveries in Fused Medical data through advanced Machine Learning technologies. \n",
    "\n",
    "Initial version is PyTorch-based and focuses on deep learning on medical imaging.\n",
    "\n",
    "\n",
    "## **FuseMedML Key Concepts in a Nutshell**\n",
    "### Share and Reuse\n",
    "\n",
    "A common generic implementation, you can reuse, is provided for most components in the pipeline. \n",
    "\n",
    "The naming convention for the common implementation is `Fuse***Default` \n",
    "\n",
    "FuseMedML comes with a large collection of components that grow with each new project. Some of them are entirely generic and the others are domain specific.\n",
    "\n",
    "\n",
    "Don't forget to **contribute** back and **share** them. \n",
    "\n",
    "### Decoupling\n",
    "The decoupling is achieved by the fact that, in most cases, the objects do not interact directly. Instead, the information and data are routed between components using *namespaces* (examples below). \n",
    "\n",
    "Meaning, each object extracts its input from and saves its output into a dictionary named `batch_dict`. \n",
    "\n",
    "`batch_dict` aggregates the outputs of all the objects through a single batch. \n",
    "\n",
    "<br />\n",
    "\n",
    "**Example of the decoupling approach:**\n",
    "```python\n",
    "FuseMetricAUC(pred_name='model.output.classification', target_name='data.gt.classification')  \n",
    "```\n",
    "\n",
    "`FuseMetricAUC` will read the required tensors to compute AUC from `batch_dict`. The relevant dictionary keys are `pred_name` and `target_name`. \n",
    "\n",
    "This approach allows writing a generic metric which is completely independent of the model and data extractor. \n",
    "\n",
    "In addition, it allows to easily re-use this object in a plug & play manner without adding extra code. \n",
    "\n",
    "Such an approach also allows us to use it several times in case we have multiple heads/tasks.\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "When a batch is completed, only the required key-value pairs from `batch_dict`, such as the loss values, will be collected in another dictionary named `epoch_results`. \n",
    "\n",
    "Both `batch_dict` and `epoch_results` are nested dictionaries. To easily access the data stored in those dictionaries, use `FuseUtilsHierarchicalDict`:\n",
    "\n",
    "```python\n",
    "FuseUtilsHierarchicalDict.get(batch_dict, ‘model.output.classification’)\n",
    "``` \n",
    "\n",
    "will return `batch_dict[‘model’][‘output’][‘classification’]`\n",
    "\n",
    "### Manager API\n",
    "The manager is the main API while using Fuse - it resposible for the Train and Infer functionallity.\n",
    "\n",
    "Possible workflows are listed in the FuseMangerDefault's documentation. Here are two examples:\n",
    "\n",
    "##### **Train: Init -> set objects -> train**\n",
    "```python\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_common_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_common_params['manager.train_params'],\n",
    "                    output_model_dir=paths['model_dir'])\n",
    "\n",
    "manager.train(train_dataloader=train_dataloader,\n",
    "                validation_dataloader=validation_dataloader)\n",
    "```\n",
    "\n",
    "##### **Infer: Init -> infer**\n",
    "```python\n",
    "manager = FuseManagerDefault()\n",
    "\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Use PyTorch directly and alternative frameworks\n",
    "\n",
    "FuseMedML uses and extends PyTorch only when required by the user. \n",
    "You can mix FuseMedML with PyTorch code, components from alternative frameworks and other popular GitHub projects. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## **Installation Details - Google Colab**\n",
    "\n",
    "#### **Enable GPU Support**\n",
    "\n",
    "To use GPU through Google Colab, change the runtime mode to GPU:\n",
    "\n",
    "From the \"Runtime\" menu select \"Change Runtime Type\", choose \"GPU\" from the drop-down menu and click \"SAVE\"\n",
    "When asked, reboot the system.\n",
    "\n",
    "#### **Install FuseMedML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/fuse-med-ml.git\n",
    "# %cd fuse-med-ml\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Setup environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from fuse.eval.evaluator import EvaluatorDefault\n",
    "from fuse.data.dataset.dataset_wrapper import FuseDatasetWrapper\n",
    "from fuse.data.sampler.sampler_balanced_batch import FuseSamplerBalancedBatch\n",
    "from fuse.losses.loss_default import FuseLossDefault\n",
    "from fuse.managers.callbacks.callback_metric_statistics import FuseMetricStatisticsCallback\n",
    "from fuse.managers.callbacks.callback_tensorboard import FuseTensorboardCallback\n",
    "from fuse.managers.callbacks.callback_time_statistics import FuseTimeStatisticsCallback\n",
    "from fuse.managers.manager_default import FuseManagerDefault\n",
    "from fuse.eval.metrics.classification.metrics_classification_common import MetricAccuracy, MetricAUCROC, MetricROCCurve\n",
    "from fuse.eval.metrics.classification.metrics_thresholding_common import MetricApplyThresholds\n",
    "from fuse.models.model_wrapper import FuseModelWrapper\n",
    "from fuse.utils.utils_gpu import FuseUtilsGPU\n",
    "from fuse.utils.utils_debug import FuseUtilsDebug\n",
    "from fuse.utils.utils_logger import fuse_logger_start\n",
    "from fuse_examples.classification.mnist.lenet import LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Setup debugger**\n",
    "The supported modes are: 'default', 'fast', 'debug', 'verbose', 'user'.\n",
    "\n",
    "More details in FuseUtilsDebug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;21m(utils_misc.py:280) WARNING: Ignoring a redefinition of the singleton of class {class_.__name__}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mode = 'default'\n",
    "debug = FuseUtilsDebug(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Output paths**\n",
    "The user is able to customize the output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'examples' # TODO: fill path here\n",
    "PATHS = {'model_dir': os.path.join(ROOT, 'mnist/model_dir'),\n",
    "         'force_reset_model_dir': True,  # If True will reset model dir automatically - otherwise will prompt 'are you sure' message.\n",
    "         'cache_dir': os.path.join(ROOT, 'mnist/cache_dir'),\n",
    "         'inference_dir': os.path.join(ROOT, 'mnist/infer_dir'),\n",
    "         'eval_dir': os.path.join(ROOT, 'mnist/eval_dir')}\n",
    "\n",
    "paths = PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training Parameters**\n",
    "* Model - which model we are using.\n",
    "* Data - define parameters for the data preproccesing.\n",
    "* Manager - define parameters for the training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COMMON_PARAMS = {}\n",
    "\n",
    "### Model ###\n",
    "TRAIN_COMMON_PARAMS['model'] = 'lenet'\n",
    "\n",
    "### Data ###\n",
    "TRAIN_COMMON_PARAMS['data.batch_size'] = 100\n",
    "TRAIN_COMMON_PARAMS['data.train_num_workers'] = 8\n",
    "TRAIN_COMMON_PARAMS['data.validation_num_workers'] = 8\n",
    "\n",
    "### Manager ###\n",
    "TRAIN_COMMON_PARAMS['manager.train_params'] = {\n",
    "    'device': 'cuda', \n",
    "    'num_epochs': 5,\n",
    "    'virtual_batch_size': 1,  # number of batches in one virtual batch\n",
    "    'start_saving_epochs': 10,  # first epoch to start saving checkpoints from\n",
    "    'gap_between_saving_epochs': 5,  # number of epochs between saved checkpoint\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.best_epoch_source'] = {\n",
    "    'source': 'metrics.accuracy',  # can be any key from 'epoch_results'\n",
    "    'optimization': 'max',  # can be either min/max\n",
    "    'on_equal_values': 'better',\n",
    "    # can be either better/worse - whether to consider best epoch when values are equal\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.learning_rate'] = 1e-4\n",
    "TRAIN_COMMON_PARAMS['manager.weight_decay'] = 0.001\n",
    "TRAIN_COMMON_PARAMS['manager.resume_checkpoint_filename'] = None  # if not None, will try to load the checkpoint\n",
    "\n",
    "train_params = TRAIN_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Allocate GPUs**\n",
    "Look for an available GPUs and allocate accordingly.\n",
    "\n",
    "To use CPU set NUM_GPUS to 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GPUS = 0\n",
    "if NUM_GPUS == 0:\n",
    "    TRAIN_COMMON_PARAMS['manager.train_params']['device'] = 'cpu' \n",
    "# uncomment if you want to use specific gpus instead of automatically looking for free ones\n",
    "force_gpus = None  # [0]\n",
    "FuseUtilsGPU.choose_and_enable_multiple_gpus(NUM_GPUS, force_gpus=force_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_softmax(output):\n",
    "    if isinstance(output, torch.Tensor):  # validation\n",
    "        logits = output\n",
    "    else:  # train\n",
    "        logits = output.logits\n",
    "    cls_preds = F.softmax(logits, dim=1)\n",
    "    return logits, cls_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Init logger**\n",
    "The logger does two things:\n",
    "- Output log automatically to three destinations:\n",
    "    1. Console\n",
    "    2. File - a copy of the console.\n",
    "    3. Verboes file - used for debug.\n",
    "\n",
    "<p></p>\n",
    "\n",
    "- Save a copy of the template file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFuse Train\u001b[0m\n",
      "\u001b[35mmodel_dir=examples/mnist/model_dir\u001b[0m\n",
      "\u001b[35mcache_dir=examples/mnist/cache_dir\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fuse_logger_start(output_path=paths['model_dir'], console_verbose_level=logging.INFO)\n",
    "lgr = logging.getLogger('Fuse')\n",
    "lgr.info('Fuse Train', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'model_dir={paths[\"model_dir\"]}', {'color': 'magenta'})\n",
    "lgr.info(f'cache_dir={paths[\"cache_dir\"]}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data**\n",
    "Downloading the MNIST dataset and building dataloaders (torch.utils.data.DataLoader) for both train and validation using Fuse components:\n",
    "1. Wrapper - **FuseDatasetWrapper**:\n",
    "\n",
    "    Wraps PyTorch dataset such that each sample is being converted to dictionary according to the provided mapping.\n",
    "2. Sampler - **FuseSamplerBalancedBatch**:\n",
    "\n",
    "    Implementing 'torch.utils.data.sampler'.\n",
    "    \n",
    "    The sampler retrieves list of samples to use for each batch.\n",
    "\n",
    "\n",
    "Other Fuse components for preprocessing data are:\n",
    "* FuseDataSourceBase\n",
    "* FuseProcessorBase\n",
    "* FuseDatasetBase\n",
    "* FuseAugmentorBase\n",
    "* FuseVisualizerBase\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain Data:\u001b[0m\n",
      "- Create sampler:\n",
      "- Create sampler: Done\n",
      "\u001b[1mTrain Data: Done\u001b[0m\n",
      "\u001b[1mValidation Data:\u001b[0m\n",
      "\u001b[1mValidation Data: Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "lgr.info(f'Train Data:', {'attrs': 'bold'})\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "# Create dataset\n",
    "torch_train_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=True, transform=transform)\n",
    "# wrapping torch dataset\n",
    "# FIXME: support also using torch dataset directly\n",
    "train_dataset = FuseDatasetWrapper(name='train', dataset=torch_train_dataset, mapping=('image', 'label'))\n",
    "train_dataset.create()\n",
    "lgr.info(f'- Create sampler:')\n",
    "sampler = FuseSamplerBalancedBatch(dataset=train_dataset,\n",
    "                                balanced_class_name='data.label',\n",
    "                                num_balanced_classes=10,\n",
    "                                batch_size=train_params['data.batch_size'],\n",
    "                                balanced_class_weights=None)\n",
    "lgr.info(f'- Create sampler: Done')\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=train_params['data.train_num_workers'])\n",
    "lgr.info(f'Train Data: Done', {'attrs': 'bold'})\n",
    "\n",
    "## Validation data\n",
    "lgr.info(f'Validation Data:', {'attrs': 'bold'})\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=train_params['data.batch_size'],\n",
    "                                num_workers=train_params['data.validation_num_workers'])\n",
    "lgr.info(f'Validation Data: Done', {'attrs': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**\n",
    "Building the LeNet model using PyTorch's API and then wrapping it. \n",
    "\n",
    "The model outputs will be aggregated in batch_dict['model.*'].\n",
    "\n",
    "\n",
    "Another option to implement a model is to use Fuse components such as:\n",
    "* FuseModelDefault\n",
    "* FuseBackbone\n",
    "* FuseHead\n",
    "* FuseModelEnsemble\n",
    "* FuseModelMultistream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel:\u001b[0m\n",
      "\u001b[1mModel: Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lgr.info('Model:', {'attrs': 'bold'})\n",
    "\n",
    "torch_model = LeNet()\n",
    "\n",
    "# use adaptive avg pooling to support mnist low resolution images\n",
    "torch_model.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "model = FuseModelWrapper(model=torch_model,\n",
    "                        model_inputs=['data.image'],\n",
    "                        post_forward_processing_function=perform_softmax,\n",
    "                        model_outputs=['logits.classification', 'output.classification']\n",
    "                        )\n",
    "\n",
    "lgr.info('Model: Done', {'attrs': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loss function**\n",
    "Dictionary of loss elements. each element is a sub-class of FuseLossBase.\n",
    "\n",
    "The total loss will be the weighted sum of all the elements.\n",
    "\n",
    "Available losses:\n",
    "* FuseLossDefault - wraps a PyTorch loss function with a Fuse api.\n",
    "* FuseLossSegmentationCrossEntropy - calculates cross entropy loss per location (\"dense\") of a class activation map (\"segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    'cls_loss': FuseLossDefault(pred_name='model.logits.classification', target_name='data.label', callable=F.cross_entropy, weight=1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Metrics**\n",
    "Dictionary of metric elements. Each element is a sub-class of FuseMetricBase.\n",
    "\n",
    "The metrics will be calculated per epoch for both the validation and train.\n",
    "\n",
    "The 'best_epoch_source', used to save the best model could be based on one of these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = OrderedDict([\n",
    "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')), # will apply argmax\n",
    "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred', target='data.label'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Callbacks**\n",
    "Callbacks are sub-classes of FuseCallbackBase.\n",
    "\n",
    "A callback is an object that can preform actions at various stages of training.\n",
    "\n",
    "In each stage it allows to manipulate either the data, batch_dict or epoch_results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # default callbacks\n",
    "    FuseTensorboardCallback(model_dir=paths['model_dir']),  # save statistics for tensorboard\n",
    "    FuseMetricStatisticsCallback(output_path=paths['model_dir'] + \"/metrics.csv\"),  # save statistics a csv file\n",
    "    FuseTimeStatisticsCallback(num_epochs=train_params['manager.train_params']['num_epochs'], load_expected_part=0.1)  # time profiler\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**\n",
    "Building Fuse's manager and supplying it PyTorch's optimizer and scheduler.\n",
    "\n",
    "Note that the manger is using the training paremeter that we've set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain:\u001b[0m\n",
      "\u001b[33mKey lr_sch_target not found in config parameter, setting value to default (train.losses.total_loss)\u001b[0m\n",
      "\u001b[1m\u001b[31mTotal number of parameters in model:1,199,882, trainable parameters:1,199,882\u001b[0m\n",
      "Train Dataset Summary:\n",
      "Class = <class 'fuse.data.dataset.dataset_wrapper.FuseDatasetWrapper'>\n",
      "Processors:\n",
      "------------------------\n",
      "<fuse.data.dataset.dataset_wrapper.DatasetProcessor object at 0x7f6223a2e890>\n",
      "Cache destination:\n",
      "------------------\n",
      "None\n",
      "Augmentor:\n",
      "----------\n",
      "None\n",
      "Data source:\n",
      "------------\n",
      "FuseDataSourceFromList - 60000 samples\n",
      "\n",
      "Sample keys:\n",
      "------------\n",
      "['data.descriptor', 'data.image', 'data.label']\n",
      "Basic Data Statistic:\n",
      "-------------------\n",
      "\n",
      "Validation Dataset Summary:\n",
      "Class = <class 'fuse.data.dataset.dataset_wrapper.FuseDatasetWrapper'>\n",
      "Processors:\n",
      "------------------------\n",
      "<fuse.data.dataset.dataset_wrapper.DatasetProcessor object at 0x7f62243cae50>\n",
      "Cache destination:\n",
      "------------------\n",
      "None\n",
      "Augmentor:\n",
      "----------\n",
      "None\n",
      "Data source:\n",
      "------------\n",
      "FuseDataSourceFromList - 10000 samples\n",
      "\n",
      "Sample keys:\n",
      "------------\n",
      "['data.descriptor', 'data.image', 'data.label']\n",
      "Basic Data Statistic:\n",
      "-------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 45.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Pre-Training:\n",
      "losses.cls_loss      = 2.3089414858818054\n",
      "losses.total_loss    = 2.3089414858818054\n",
      "metrics.accuracy     = 0.12\n",
      "metrics.operation_point.cls_pred = <fuse.eval.metrics.utils.PerSampleData object at 0x7f62234de2d0>\n",
      "Start training on epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:26<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 56.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThis is the best epoch ever (metrics.accuracy = 0.945)\u001b[0m\n",
      "\u001b[1m\u001b[4mStats for epoch: 1 (Currently the best epoch for source metrics.accuracy!)\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 | Best Epoch Value                | Current Epoch Validation        | Current Epoch Train             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss                 | 0.1220                          | 0.1220                          | 0.4344                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss               | 0.1220                          | 0.1220                          | 0.4344                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy                | 0.9450                          | 0.9450                          | 0.8630                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.operation_point.cls_pred| N/A                             | N/A                             | N/A                             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 2 minutes, 2 seconds (last epoch time: 30 seconds)\u001b[0m\n",
      "Start training on epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:26<00:00, 25.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 64.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThis is the best epoch ever (metrics.accuracy = 0.975)\u001b[0m\n",
      "\u001b[1m\u001b[4mStats for epoch: 2 (Currently the best epoch for source metrics.accuracy!)\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 | Best Epoch Value                | Current Epoch Validation        | Current Epoch Train             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss                 | 0.0668                          | 0.0668                          | 0.1571                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss               | 0.0668                          | 0.0668                          | 0.1571                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy                | 0.9750                          | 0.9750                          | 0.9541                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.operation_point.cls_pred| N/A                             | N/A                             | N/A                             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 1 minute, 32 seconds (last epoch time: 30 seconds)\u001b[0m\n",
      "Start training on epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:26<00:00, 25.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 57.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThis is the best epoch ever (metrics.accuracy = 0.98)\u001b[0m\n",
      "\u001b[1m\u001b[4mStats for epoch: 3 (Currently the best epoch for source metrics.accuracy!)\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 | Best Epoch Value                | Current Epoch Validation        | Current Epoch Train             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss                 | 0.0529                          | 0.0529                          | 0.1113                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss               | 0.0529                          | 0.0529                          | 0.1113                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy                | 0.9800                          | 0.9800                          | 0.9667                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.operation_point.cls_pred| N/A                             | N/A                             | N/A                             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 1 minute, 1 second (last epoch time: 30 seconds)\u001b[0m\n",
      "Start training on epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:26<00:00, 25.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation on epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 57.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThis is the best epoch ever (metrics.accuracy = 0.985)\u001b[0m\n",
      "\u001b[1m\u001b[4mStats for epoch: 4 (Currently the best epoch for source metrics.accuracy!)\u001b[0m\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "|                                 | Best Epoch Value                | Current Epoch Validation        | Current Epoch Train             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.cls_loss                 | 0.0451                          | 0.0451                          | 0.0902                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| losses.total_loss               | 0.0451                          | 0.0451                          | 0.0902                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.accuracy                | 0.9850                          | 0.9850                          | 0.9726                          |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "| metrics.operation_point.cls_pred| N/A                             | N/A                             | N/A                             |\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: examples/mnist/model_dir\n",
      "\u001b[36mEstimated time left: 31 seconds (last epoch time: 31 seconds)\u001b[0m\n",
      "\u001b[1mTrain: Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lgr.info('Train:', {'attrs': 'bold'})\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_params['manager.learning_rate'], weight_decay=train_params['manager.weight_decay'])\n",
    "\n",
    "# create scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# train from scratch\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "\n",
    "# Providing the objects required for the training process.\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_params['manager.train_params'])\n",
    "\n",
    "## Continue training\n",
    "if train_params['manager.resume_checkpoint_filename'] is not None:\n",
    "    # Loading the checkpoint including model weights, learning rate, and epoch_index.\n",
    "    manager.load_checkpoint(checkpoint=train_params['manager.resume_checkpoint_filename'], mode='train')\n",
    "\n",
    "# Start training\n",
    "manager.train(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader)\n",
    "\n",
    "lgr.info('Train: Done', {'attrs': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Infer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_COMMON_PARAMS = {}\n",
    "INFER_COMMON_PARAMS['infer_filename'] = 'validation_set_infer.gz'\n",
    "INFER_COMMON_PARAMS['checkpoint'] = 'best'  # Fuse TIP: possible values are 'best', 'last' or epoch_index.\n",
    "\n",
    "infer_common_params = INFER_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFuse Inference\u001b[0m\n",
      "\u001b[35minfer_filename=examples/mnist/infer_dir/validation_set_infer.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lgr.info('Fuse Inference', {'attrs': ['bold', 'underline']})\n",
    "lgr.info(f'infer_filename={os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"])}', {'color': 'magenta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: examples/mnist/model_dir\n",
      "\u001b[33mLoading checkpoint file: examples/mnist/model_dir/checkpoint_best_0_epoch.pth. values_to_resume all\u001b[0m\n",
      "\u001b[33mKey device not found in config parameter, setting value to default (cuda)\u001b[0m\n",
      "\u001b[33mKey virtual_batch_size not found in config parameter, setting value to default (1)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:15<00:00, 325.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save inference results into examples/mnist/infer_dir/validation_set_infer.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descriptor</th>\n",
       "      <th>id</th>\n",
       "      <th>model.output.classification</th>\n",
       "      <th>data.label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(validation, 0)</td>\n",
       "      <td>(validation, 0)</td>\n",
       "      <td>[5.138777e-07, 1.4041168e-06, 2.6891832e-06, 5...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(validation, 1)</td>\n",
       "      <td>(validation, 1)</td>\n",
       "      <td>[1.0900631e-05, 4.0194295e-06, 0.9999697, 9.21...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(validation, 2)</td>\n",
       "      <td>(validation, 2)</td>\n",
       "      <td>[2.3092376e-05, 0.99918514, 0.00023841466, 1.5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(validation, 3)</td>\n",
       "      <td>(validation, 3)</td>\n",
       "      <td>[0.99988127, 1.0185969e-06, 7.6026945e-06, 4.8...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(validation, 4)</td>\n",
       "      <td>(validation, 4)</td>\n",
       "      <td>[9.574807e-07, 2.1989351e-06, 8.762338e-07, 5....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>(validation, 9995)</td>\n",
       "      <td>(validation, 9995)</td>\n",
       "      <td>[1.7930368e-08, 1.1795048e-05, 0.9999552, 1.09...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>(validation, 9996)</td>\n",
       "      <td>(validation, 9996)</td>\n",
       "      <td>[2.8840468e-06, 7.130423e-06, 1.923636e-05, 0....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>(validation, 9997)</td>\n",
       "      <td>(validation, 9997)</td>\n",
       "      <td>[3.5204263e-08, 5.910253e-06, 2.834256e-08, 8....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>(validation, 9998)</td>\n",
       "      <td>(validation, 9998)</td>\n",
       "      <td>[3.637482e-07, 5.0382685e-08, 2.3517039e-07, 1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>(validation, 9999)</td>\n",
       "      <td>(validation, 9999)</td>\n",
       "      <td>[7.2226917e-06, 8.6148715e-09, 1.8357034e-05, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              descriptor                  id  \\\n",
       "0        (validation, 0)     (validation, 0)   \n",
       "1        (validation, 1)     (validation, 1)   \n",
       "2        (validation, 2)     (validation, 2)   \n",
       "3        (validation, 3)     (validation, 3)   \n",
       "4        (validation, 4)     (validation, 4)   \n",
       "...                  ...                 ...   \n",
       "9995  (validation, 9995)  (validation, 9995)   \n",
       "9996  (validation, 9996)  (validation, 9996)   \n",
       "9997  (validation, 9997)  (validation, 9997)   \n",
       "9998  (validation, 9998)  (validation, 9998)   \n",
       "9999  (validation, 9999)  (validation, 9999)   \n",
       "\n",
       "                            model.output.classification  data.label  \n",
       "0     [5.138777e-07, 1.4041168e-06, 2.6891832e-06, 5...           7  \n",
       "1     [1.0900631e-05, 4.0194295e-06, 0.9999697, 9.21...           2  \n",
       "2     [2.3092376e-05, 0.99918514, 0.00023841466, 1.5...           1  \n",
       "3     [0.99988127, 1.0185969e-06, 7.6026945e-06, 4.8...           0  \n",
       "4     [9.574807e-07, 2.1989351e-06, 8.762338e-07, 5....           4  \n",
       "...                                                 ...         ...  \n",
       "9995  [1.7930368e-08, 1.1795048e-05, 0.9999552, 1.09...           2  \n",
       "9996  [2.8840468e-06, 7.130423e-06, 1.923636e-05, 0....           3  \n",
       "9997  [3.5204263e-08, 5.910253e-06, 2.834256e-08, 8....           4  \n",
       "9998  [3.637482e-07, 5.0382685e-08, 2.3517039e-07, 1...           5  \n",
       "9999  [7.2226917e-06, 8.6148715e-09, 1.8357034e-05, ...           6  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataloader = DataLoader(dataset=validation_dataset, collate_fn=validation_dataset.collate_fn, batch_size=2, num_workers=2)\n",
    "\n",
    "## Manager for inference\n",
    "manager = FuseManagerDefault()\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define EVAL Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_COMMON_PARAMS = {}\n",
    "EVAL_COMMON_PARAMS['infer_filename'] = INFER_COMMON_PARAMS['infer_filename']\n",
    "eval_common_params = EVAL_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Calculate metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mFuse Evaluate\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgr.info('Fuse Evaluate', {'attrs': ['bold', 'underline']})\n",
    "\n",
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "# metrics\n",
    "metrics = OrderedDict([\n",
    "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')), # will apply argmax\n",
    "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred', target='data.label')),\n",
    "    ('roc', MetricROCCurve(pred='model.output.classification', target='data.label', class_names=class_names, output_filename=os.path.join(paths['inference_dir'], 'roc_curve.png'))),\n",
    "    ('auc', MetricAUCROC(pred='model.output.classification', target='data.label', class_names=class_names)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "Metric operation_point:\n",
      "------------------------------------------------\n",
      "cls_pred:\n",
      "<fuse.eval.metrics.utils.PerSampleData object at 0x7f6224b150d0>\n",
      "\n",
      "Metric accuracy:\n",
      "------------------------------------------------\n",
      "0.9852\n",
      "\n",
      "Metric roc:\n",
      "------------------------------------------------\n",
      "0.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.10864745e-04 1.10864745e-04 2.21729490e-04 2.21729490e-04\n",
      " 3.32594235e-04 3.32594235e-04 4.43458980e-04 4.43458980e-04\n",
      " 5.54323725e-04 5.54323725e-04 6.65188470e-04 6.65188470e-04\n",
      " 9.97782705e-04 9.97782705e-04 1.21951220e-03 1.21951220e-03\n",
      " 1.55210643e-03 1.55210643e-03 1.77383592e-03 1.77383592e-03\n",
      " 1.99556541e-03 1.99556541e-03 2.32815965e-03 2.32815965e-03\n",
      " 2.88248337e-03 2.88248337e-03 4.21286031e-03 4.21286031e-03\n",
      " 4.65631929e-03 4.65631929e-03 9.20177384e-03 9.20177384e-03\n",
      " 6.62749446e-01 6.62971175e-01 1.00000000e+00]\n",
      "0.tpr:\n",
      "[0.         0.00102041 0.00408163 0.00714286 0.01020408 0.0122449\n",
      " 0.01326531 0.01632653 0.01734694 0.02040816 0.02244898 0.0255102\n",
      " 0.03061224 0.03367347 0.03673469 0.03979592 0.04183673 0.04489796\n",
      " 0.04693878 0.05       0.05306122 0.05918367 0.06326531 0.06530612\n",
      " 0.06734694 0.06938776 0.07142857 0.0755102  0.07857143 0.08163265\n",
      " 0.0877551  0.09387755 0.09489796 0.09897959 0.1        0.10408163\n",
      " 0.10612245 0.11020408 0.11632653 0.11734694 0.11938776 0.12346939\n",
      " 0.13061224 0.13163265 0.1377551  0.13877551 0.14183673 0.14795918\n",
      " 0.15       0.15408163 0.15714286 0.15918367 0.16122449 0.16428571\n",
      " 0.16530612 0.16734694 0.16836735 0.1744898  0.17959184 0.18061224\n",
      " 0.18265306 0.18673469 0.19081633 0.19183673 0.19489796 0.19591837\n",
      " 0.20408163 0.20612245 0.20918367 0.21122449 0.21530612 0.21734694\n",
      " 0.22040816 0.22244898 0.2255102  0.22653061 0.22857143 0.23061224\n",
      " 0.24081633 0.24693878 0.24897959 0.25102041 0.25408163 0.25612245\n",
      " 0.25714286 0.25918367 0.26326531 0.26938776 0.27040816 0.27244898\n",
      " 0.27653061 0.27857143 0.28061224 0.28469388 0.28673469 0.28877551\n",
      " 0.29489796 0.29693878 0.3        0.30204082 0.30408163 0.30714286\n",
      " 0.30918367 0.31122449 0.31326531 0.31836735 0.32040816 0.32755102\n",
      " 0.32959184 0.33163265 0.33367347 0.33571429 0.3377551  0.34387755\n",
      " 0.34795918 0.35       0.35306122 0.35612245 0.35816327 0.35918367\n",
      " 0.36530612 0.36632653 0.36836735 0.37040816 0.37346939 0.3755102\n",
      " 0.37755102 0.38061224 0.38265306 0.38469388 0.38673469 0.39183673\n",
      " 0.39489796 0.39693878 0.40102041 0.42040816 0.42244898 0.42653061\n",
      " 0.42857143 0.43061224 0.43367347 0.44693878 0.45       0.45816327\n",
      " 0.46020408 0.46428571 0.46632653 0.47653061 0.47857143 0.48877551\n",
      " 0.49285714 0.52857143 0.53061224 0.53163265 0.53367347 0.54387755\n",
      " 0.54591837 0.5622449  0.56428571 0.5755102  0.57755102 0.59897959\n",
      " 0.60102041 0.62653061 0.62857143 0.64285714 0.64489796 0.66122449\n",
      " 0.66326531 0.66428571 0.66632653 0.68061224 0.68265306 0.68673469\n",
      " 0.68877551 0.71428571 0.71632653 0.77346939 0.7755102  0.83979592\n",
      " 0.83979592 0.95102041 0.95102041 0.97653061 0.97653061 0.98163265\n",
      " 0.98163265 0.98469388 0.98469388 0.98673469 0.98673469 0.9877551\n",
      " 0.9877551  0.98877551 0.98877551 0.98979592 0.98979592 0.99183673\n",
      " 0.99183673 0.99285714 0.99285714 0.99387755 0.99387755 0.99489796\n",
      " 0.99489796 0.99693878 0.99693878 0.99795918 0.99795918 0.99897959\n",
      " 0.99897959 1.         1.         1.         1.        ]\n",
      "0.auc:\n",
      "0.9999411738087697\n",
      "1.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.12803158e-04 1.12803158e-04 2.25606317e-04\n",
      " 2.25606317e-04 4.51212634e-04 4.51212634e-04 6.76818951e-04\n",
      " 6.76818951e-04 7.89622109e-04 7.89622109e-04 1.46644106e-03\n",
      " 1.46644106e-03 1.57924422e-03 1.57924422e-03 1.69204738e-03\n",
      " 1.69204738e-03 1.91765369e-03 1.91765369e-03 2.03045685e-03\n",
      " 2.03045685e-03 2.36886633e-03 2.36886633e-03 2.59447265e-03\n",
      " 2.59447265e-03 3.04568528e-03 3.04568528e-03 4.96333897e-03\n",
      " 4.96333897e-03 4.20304569e-01 4.20530175e-01 1.00000000e+00]\n",
      "1.tpr:\n",
      "[0.00000000e+00 8.81057269e-04 3.52422907e-03 5.28634361e-03\n",
      " 1.32158590e-02 1.49779736e-02 2.64317181e-02 2.81938326e-02\n",
      " 4.14096916e-02 4.31718062e-02 4.84581498e-02 5.02202643e-02\n",
      " 8.89867841e-02 9.07488987e-02 9.33920705e-02 9.51541850e-02\n",
      " 1.17180617e-01 1.18942731e-01 1.32158590e-01 1.35682819e-01\n",
      " 1.36563877e-01 1.38325991e-01 1.47136564e-01 1.48898678e-01\n",
      " 1.49779736e-01 1.51541850e-01 1.71806167e-01 1.73568282e-01\n",
      " 1.82378855e-01 1.84140969e-01 1.87665198e-01 1.89427313e-01\n",
      " 2.04405286e-01 2.06167401e-01 2.09691630e-01 2.11453744e-01\n",
      " 2.22907489e-01 2.24669604e-01 2.26431718e-01 2.29955947e-01\n",
      " 2.51982379e-01 2.55506608e-01 2.65198238e-01 2.66960352e-01\n",
      " 2.83700441e-01 2.85462555e-01 2.91629956e-01 2.93392070e-01\n",
      " 3.03083700e-01 3.04845815e-01 3.06607930e-01 3.08370044e-01\n",
      " 3.11894273e-01 3.13656388e-01 3.17180617e-01 3.18942731e-01\n",
      " 3.20704846e-01 3.22466960e-01 3.40969163e-01 3.42731278e-01\n",
      " 3.50660793e-01 3.52422907e-01 3.55947137e-01 3.57709251e-01\n",
      " 3.63876652e-01 3.65638767e-01 3.91189427e-01 3.92951542e-01\n",
      " 4.01762115e-01 4.03524229e-01 4.07929515e-01 4.09691630e-01\n",
      " 4.11453744e-01 4.13215859e-01 4.29955947e-01 4.31718062e-01\n",
      " 4.34361233e-01 4.36123348e-01 4.86343612e-01 4.88105727e-01\n",
      " 6.91629956e-01 6.93392070e-01 7.08370044e-01 7.10132159e-01\n",
      " 9.34801762e-01 9.34801762e-01 9.77973568e-01 9.77973568e-01\n",
      " 9.79735683e-01 9.79735683e-01 9.85903084e-01 9.85903084e-01\n",
      " 9.86784141e-01 9.86784141e-01 9.88546256e-01 9.88546256e-01\n",
      " 9.89427313e-01 9.89427313e-01 9.91189427e-01 9.91189427e-01\n",
      " 9.92070485e-01 9.92070485e-01 9.95594714e-01 9.95594714e-01\n",
      " 9.96475771e-01 9.96475771e-01 9.97356828e-01 9.97356828e-01\n",
      " 9.98237885e-01 9.98237885e-01 9.99118943e-01 9.99118943e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "1.auc:\n",
      "0.9999644197967059\n",
      "2.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.11507583e-04\n",
      " 1.11507583e-04 2.23015165e-04 2.23015165e-04 3.34522748e-04\n",
      " 3.34522748e-04 4.46030330e-04 4.46030330e-04 6.69045495e-04\n",
      " 6.69045495e-04 7.80553078e-04 7.80553078e-04 8.92060660e-04\n",
      " 8.92060660e-04 1.00356824e-03 1.00356824e-03 1.22658341e-03\n",
      " 1.22658341e-03 1.44959857e-03 1.44959857e-03 1.56110616e-03\n",
      " 1.56110616e-03 1.89562890e-03 1.89562890e-03 2.00713649e-03\n",
      " 2.00713649e-03 2.11864407e-03 2.11864407e-03 2.23015165e-03\n",
      " 2.23015165e-03 2.89919715e-03 2.89919715e-03 3.01070473e-03\n",
      " 3.01070473e-03 3.45673506e-03 3.45673506e-03 4.34879572e-03\n",
      " 4.34879572e-03 6.02140946e-03 6.02140946e-03 6.24442462e-03\n",
      " 6.24442462e-03 7.13648528e-03 7.13648528e-03 8.02854594e-03\n",
      " 8.02854594e-03 3.21364853e-01 3.21587868e-01 1.00000000e+00]\n",
      "2.tpr:\n",
      "[0.         0.00193798 0.00387597 0.00775194 0.00968992 0.01356589\n",
      " 0.01744186 0.01937984 0.02228682 0.02616279 0.03003876 0.03197674\n",
      " 0.04360465 0.04554264 0.05813953 0.06007752 0.06104651 0.06492248\n",
      " 0.06782946 0.06976744 0.07655039 0.07848837 0.08914729 0.09302326\n",
      " 0.10271318 0.10465116 0.12790698 0.13178295 0.13372093 0.13565891\n",
      " 0.15697674 0.15891473 0.1627907  0.16472868 0.17151163 0.1753876\n",
      " 0.19864341 0.2005814  0.25290698 0.25484496 0.2877907  0.28972868\n",
      " 0.33333333 0.33527132 0.39437984 0.39631783 0.40116279 0.40310078\n",
      " 0.59205426 0.59399225 0.87015504 0.87015504 0.91085271 0.91085271\n",
      " 0.93507752 0.93507752 0.94089147 0.94089147 0.94282946 0.94282946\n",
      " 0.94573643 0.94573643 0.95639535 0.95639535 0.95833333 0.95833333\n",
      " 0.97383721 0.97383721 0.97577519 0.97577519 0.97771318 0.97771318\n",
      " 0.98352713 0.98352713 0.98449612 0.98449612 0.98546512 0.98546512\n",
      " 0.98643411 0.98643411 0.9874031  0.9874031  0.99127907 0.99127907\n",
      " 0.99224806 0.99224806 0.99321705 0.99321705 0.99515504 0.99515504\n",
      " 0.99709302 0.99709302 0.99806202 0.99806202 0.99903101 0.99903101\n",
      " 1.         1.         1.         1.        ]\n",
      "2.auc:\n",
      "0.9998790920689583\n",
      "3.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.11234705e-04 1.11234705e-04\n",
      " 2.22469410e-04 2.22469410e-04 3.33704116e-04 3.33704116e-04\n",
      " 4.44938821e-04 4.44938821e-04 5.56173526e-04 5.56173526e-04\n",
      " 6.67408231e-04 6.67408231e-04 7.78642937e-04 7.78642937e-04\n",
      " 1.11234705e-03 1.11234705e-03 1.33481646e-03 1.33481646e-03\n",
      " 1.55728587e-03 1.55728587e-03 1.66852058e-03 1.66852058e-03\n",
      " 1.77975528e-03 1.77975528e-03 2.33592881e-03 2.33592881e-03\n",
      " 2.55839822e-03 2.55839822e-03 2.66963293e-03 2.66963293e-03\n",
      " 5.22803115e-03 5.22803115e-03 5.33926585e-03 5.33926585e-03\n",
      " 6.34037820e-03 6.34037820e-03 1.20133482e-02 1.20133482e-02\n",
      " 1.00000000e+00]\n",
      "3.tpr:\n",
      "[0.00000000e+00 9.90099010e-04 2.97029703e-03 3.96039604e-03\n",
      " 7.92079208e-03 9.90099010e-03 1.38613861e-02 1.68316832e-02\n",
      " 1.78217822e-02 2.17821782e-02 2.37623762e-02 2.77227723e-02\n",
      " 2.87128713e-02 3.06930693e-02 3.46534653e-02 3.66336634e-02\n",
      " 4.05940594e-02 4.25742574e-02 4.35643564e-02 4.75247525e-02\n",
      " 4.85148515e-02 5.04950495e-02 5.14851485e-02 5.34653465e-02\n",
      " 5.54455446e-02 5.94059406e-02 6.03960396e-02 6.23762376e-02\n",
      " 6.53465347e-02 6.73267327e-02 7.02970297e-02 7.22772277e-02\n",
      " 7.52475248e-02 7.92079208e-02 8.21782178e-02 8.31683168e-02\n",
      " 8.51485149e-02 8.61386139e-02 8.81188119e-02 9.00990099e-02\n",
      " 9.20792079e-02 9.30693069e-02 9.50495050e-02 9.70297030e-02\n",
      " 9.90099010e-02 1.02970297e-01 1.04950495e-01 1.07920792e-01\n",
      " 1.09900990e-01 1.13861386e-01 1.15841584e-01 1.19801980e-01\n",
      " 1.21782178e-01 1.34653465e-01 1.36633663e-01 1.38613861e-01\n",
      " 1.40594059e-01 1.42574257e-01 1.44554455e-01 1.48514851e-01\n",
      " 1.50495050e-01 1.55445545e-01 1.57425743e-01 1.60396040e-01\n",
      " 1.62376238e-01 1.67326733e-01 1.69306931e-01 1.70297030e-01\n",
      " 1.72277228e-01 1.75247525e-01 1.81188119e-01 1.83168317e-01\n",
      " 1.93069307e-01 1.96039604e-01 1.98019802e-01 2.03960396e-01\n",
      " 2.05940594e-01 2.07920792e-01 2.09900990e-01 2.29702970e-01\n",
      " 2.31683168e-01 2.32673267e-01 2.35643564e-01 2.39603960e-01\n",
      " 2.41584158e-01 2.48514851e-01 2.50495050e-01 2.67326733e-01\n",
      " 2.69306931e-01 2.71287129e-01 2.73267327e-01 2.85148515e-01\n",
      " 2.89108911e-01 3.03960396e-01 3.05940594e-01 3.09900990e-01\n",
      " 3.11881188e-01 3.13861386e-01 3.15841584e-01 3.17821782e-01\n",
      " 3.19801980e-01 3.48514851e-01 3.50495050e-01 3.53465347e-01\n",
      " 3.55445545e-01 3.95049505e-01 3.97029703e-01 4.02970297e-01\n",
      " 4.04950495e-01 4.14851485e-01 4.18811881e-01 5.14851485e-01\n",
      " 5.16831683e-01 5.22772277e-01 5.24752475e-01 5.36633663e-01\n",
      " 5.38613861e-01 5.52475248e-01 5.54455446e-01 7.89108911e-01\n",
      " 7.91089109e-01 9.56435644e-01 9.56435644e-01 9.64356436e-01\n",
      " 9.64356436e-01 9.65346535e-01 9.65346535e-01 9.69306931e-01\n",
      " 9.69306931e-01 9.75247525e-01 9.75247525e-01 9.76237624e-01\n",
      " 9.76237624e-01 9.77227723e-01 9.77227723e-01 9.80198020e-01\n",
      " 9.80198020e-01 9.85148515e-01 9.85148515e-01 9.86138614e-01\n",
      " 9.86138614e-01 9.88118812e-01 9.88118812e-01 9.91089109e-01\n",
      " 9.91089109e-01 9.92079208e-01 9.92079208e-01 9.94059406e-01\n",
      " 9.94059406e-01 9.95049505e-01 9.95049505e-01 9.96039604e-01\n",
      " 9.96039604e-01 9.97029703e-01 9.97029703e-01 9.98019802e-01\n",
      " 9.98019802e-01 9.99009901e-01 9.99009901e-01 1.00000000e+00\n",
      " 1.00000000e+00]\n",
      "3.auc:\n",
      "0.9999363429112655\n",
      "4.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.10889332e-04 1.10889332e-04 2.21778665e-04 2.21778665e-04\n",
      " 3.32667997e-04 3.32667997e-04 4.43557330e-04 4.43557330e-04\n",
      " 5.54446662e-04 5.54446662e-04 6.65335995e-04 6.65335995e-04\n",
      " 7.76225327e-04 7.76225327e-04 8.87114660e-04 8.87114660e-04\n",
      " 9.98003992e-04 9.98003992e-04 1.44156132e-03 1.44156132e-03\n",
      " 1.66333999e-03 1.66333999e-03 1.77422932e-03 1.77422932e-03\n",
      " 1.88511865e-03 1.88511865e-03 2.55045465e-03 2.55045465e-03\n",
      " 3.10490131e-03 3.10490131e-03 3.21579064e-03 3.21579064e-03\n",
      " 3.99201597e-03 3.99201597e-03 6.09891328e-03 6.09891328e-03\n",
      " 1.00000000e+00]\n",
      "4.tpr:\n",
      "[0.         0.00203666 0.00305499 0.00509165 0.00610998 0.00814664\n",
      " 0.0101833  0.01221996 0.01323829 0.01934827 0.02138493 0.02953157\n",
      " 0.03156823 0.03360489 0.03665988 0.03767821 0.03971487 0.0407332\n",
      " 0.04378819 0.04684318 0.04887984 0.0509165  0.05295316 0.05702648\n",
      " 0.0610998  0.06211813 0.06517312 0.07026477 0.07331976 0.07637475\n",
      " 0.07841141 0.08350305 0.08553971 0.0885947  0.09063136 0.09266802\n",
      " 0.09470468 0.10081466 0.10285132 0.10488798 0.10692464 0.10794297\n",
      " 0.11099796 0.11201629 0.11405295 0.13034623 0.13340122 0.13645621\n",
      " 0.13849287 0.14154786 0.14765784 0.1496945  0.15173116 0.15580448\n",
      " 0.15784114 0.1598778  0.16191446 0.16496945 0.16700611 0.1700611\n",
      " 0.17209776 0.17718941 0.17922607 0.18839104 0.1904277  0.200611\n",
      " 0.20264766 0.20468432 0.20672098 0.20773931 0.20977597 0.2107943\n",
      " 0.21283096 0.21384929 0.21588595 0.22708758 0.22912424 0.23014257\n",
      " 0.23217923 0.24439919 0.24643585 0.25050916 0.25254582 0.25661914\n",
      " 0.2586558  0.26680244 0.27291242 0.27698574 0.2790224  0.28004073\n",
      " 0.28411405 0.29124236 0.29327902 0.29633401 0.29837067 0.35845214\n",
      " 0.3604888  0.36252546 0.36456212 0.37678208 0.37881874 0.41751527\n",
      " 0.41955193 0.45723014 0.4592668  0.47046843 0.47250509 0.57841141\n",
      " 0.58044807 0.60183299 0.60386965 0.63136456 0.63340122 0.78411405\n",
      " 0.78615071 0.88492872 0.88492872 0.93279022 0.93279022 0.93788187\n",
      " 0.93788187 0.97250509 0.97250509 0.97861507 0.97861507 0.9796334\n",
      " 0.9796334  0.98370672 0.98370672 0.98676171 0.98676171 0.98879837\n",
      " 0.98879837 0.9898167  0.9898167  0.99083503 0.99083503 0.99185336\n",
      " 0.99185336 0.99287169 0.99287169 0.99490835 0.99490835 0.99592668\n",
      " 0.99592668 0.99694501 0.99694501 0.99796334 0.99796334 0.99898167\n",
      " 0.99898167 1.         1.        ]\n",
      "4.auc:\n",
      "0.9999427485829429\n",
      "5.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.09793588e-04 1.09793588e-04\n",
      " 2.19587176e-04 2.19587176e-04 3.29380764e-04 3.29380764e-04\n",
      " 4.39174352e-04 4.39174352e-04 5.48967940e-04 5.48967940e-04\n",
      " 7.68555116e-04 7.68555116e-04 1.09793588e-03 1.09793588e-03\n",
      " 1.53711023e-03 1.53711023e-03 1.64690382e-03 1.64690382e-03\n",
      " 2.74483970e-03 2.74483970e-03 3.51339482e-03 3.51339482e-03\n",
      " 3.84277558e-03 3.84277558e-03 4.06236276e-03 4.06236276e-03\n",
      " 4.28194993e-03 4.28194993e-03 5.37988581e-03 5.37988581e-03\n",
      " 1.53711023e-02 1.53711023e-02 1.00000000e+00]\n",
      "5.tpr:\n",
      "[0.         0.00112108 0.00560538 0.00896861 0.01121076 0.01457399\n",
      " 0.01681614 0.0190583  0.02242152 0.02466368 0.02690583 0.03026906\n",
      " 0.03699552 0.04147982 0.04484305 0.04596413 0.04820628 0.05269058\n",
      " 0.05605381 0.05829596 0.06053812 0.06278027 0.06502242 0.06726457\n",
      " 0.0706278  0.07174888 0.07399103 0.07735426 0.07959641 0.08183857\n",
      " 0.08408072 0.08632287 0.0896861  0.09192825 0.09529148 0.09865471\n",
      " 0.10089686 0.10201794 0.10762332 0.10874439 0.1132287  0.11434978\n",
      " 0.117713   0.12107623 0.12331839 0.12892377 0.13565022 0.1367713\n",
      " 0.14125561 0.14237668 0.14686099 0.1558296  0.15807175 0.1603139\n",
      " 0.16255605 0.16367713 0.16591928 0.17488789 0.17825112 0.18049327\n",
      " 0.18273543 0.18834081 0.19058296 0.19618834 0.19955157 0.20067265\n",
      " 0.2029148  0.20515695 0.2073991  0.2309417  0.23542601 0.24663677\n",
      " 0.24887892 0.26345291 0.26569507 0.27242152 0.27466368 0.29035874\n",
      " 0.2926009  0.32511211 0.32735426 0.36883408 0.37107623 0.38116592\n",
      " 0.38340807 0.39237668 0.39686099 0.43609865 0.43834081 0.45627803\n",
      " 0.45852018 0.59865471 0.60089686 0.89686099 0.89686099 0.94394619\n",
      " 0.94394619 0.97197309 0.97197309 0.9809417  0.9809417  0.98430493\n",
      " 0.98430493 0.98542601 0.98542601 0.98654709 0.98654709 0.98766816\n",
      " 0.98766816 0.98878924 0.98878924 0.98991031 0.98991031 0.99215247\n",
      " 0.99215247 0.99439462 0.99439462 0.9955157  0.9955157  0.99663677\n",
      " 0.99663677 0.99775785 0.99775785 0.99887892 0.99887892 1.\n",
      " 1.        ]\n",
      "5.auc:\n",
      "0.9999270094196006\n",
      "6.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.10595001e-04 1.10595001e-04\n",
      " 2.21190002e-04 2.21190002e-04 3.31785003e-04 3.31785003e-04\n",
      " 4.42380004e-04 4.42380004e-04 5.52975006e-04 5.52975006e-04\n",
      " 7.74165008e-04 7.74165008e-04 1.10595001e-03 1.10595001e-03\n",
      " 1.32714001e-03 1.32714001e-03 1.65892502e-03 1.65892502e-03\n",
      " 1.76952002e-03 1.76952002e-03 1.88011502e-03 1.88011502e-03\n",
      " 2.32249502e-03 2.32249502e-03 2.43309002e-03 2.43309002e-03\n",
      " 2.54368503e-03 2.54368503e-03 4.20261004e-03 4.20261004e-03\n",
      " 4.64499005e-03 4.64499005e-03 1.10595001e-02 1.10595001e-02\n",
      " 2.22295952e-02 2.22295952e-02 3.05242203e-02 3.05242203e-02\n",
      " 4.10307454e-02 4.10307454e-02 9.15284229e-01 9.15505419e-01\n",
      " 1.00000000e+00]\n",
      "6.tpr:\n",
      "[0.         0.00104384 0.01148225 0.01461378 0.01878914 0.02087683\n",
      " 0.02713987 0.0302714  0.03131524 0.03862213 0.04279749 0.04697286\n",
      " 0.05323591 0.05532359 0.06158664 0.06367432 0.07411273 0.07515658\n",
      " 0.07724426 0.08246347 0.08663883 0.09185804 0.09394572 0.09498956\n",
      " 0.09707724 0.10020877 0.10125261 0.10438413 0.10647182 0.1085595\n",
      " 0.10960334 0.11377871 0.11482255 0.12004175 0.12212944 0.12526096\n",
      " 0.13152401 0.13256785 0.13778706 0.14509395 0.14822547 0.15240084\n",
      " 0.15866388 0.16283925 0.16701461 0.16805846 0.17118998 0.17223382\n",
      " 0.17849687 0.18162839 0.18789144 0.19206681 0.19624217 0.1993737\n",
      " 0.20250522 0.20668058 0.20981211 0.21294363 0.21607516 0.21816284\n",
      " 0.22129436 0.22442589 0.22755741 0.23068894 0.23277662 0.23903967\n",
      " 0.24112735 0.24425887 0.24634656 0.24947808 0.25156576 0.25574113\n",
      " 0.25887265 0.26304802 0.2651357  0.26826722 0.27244259 0.27453027\n",
      " 0.27661795 0.28183716 0.28392484 0.28601253 0.29227557 0.29958246\n",
      " 0.30375783 0.31002088 0.31628392 0.31837161 0.32045929 0.33402923\n",
      " 0.33611691 0.33716075 0.33924843 0.37160752 0.3736952  0.38726514\n",
      " 0.38935282 0.40292276 0.40501044 0.43110647 0.43319415 0.43736952\n",
      " 0.4394572  0.45093946 0.45302714 0.45407098 0.45615866 0.46033403\n",
      " 0.46242171 0.46346555 0.46555324 0.4697286  0.47181628 0.48121086\n",
      " 0.48538622 0.49686848 0.49895616 0.52087683 0.52296451 0.5302714\n",
      " 0.53235908 0.53653445 0.53862213 0.65762004 0.65970772 0.93319415\n",
      " 0.93319415 0.96242171 0.96242171 0.9697286  0.9697286  0.97703549\n",
      " 0.97703549 0.97912317 0.97912317 0.98016701 0.98016701 0.98121086\n",
      " 0.98121086 0.98329854 0.98329854 0.98434238 0.98434238 0.98643006\n",
      " 0.98643006 0.9874739  0.9874739  0.98851775 0.98851775 0.98956159\n",
      " 0.98956159 0.99164927 0.99164927 0.99373695 0.99373695 0.99478079\n",
      " 0.99478079 0.99582463 0.99582463 0.99686848 0.99686848 0.99791232\n",
      " 0.99791232 0.99895616 0.99895616 1.         1.         1.\n",
      " 1.        ]\n",
      "6.auc:\n",
      "0.9998479607343878\n",
      "7.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.11457869e-04 1.11457869e-04\n",
      " 2.22915738e-04 2.22915738e-04 3.34373607e-04 3.34373607e-04\n",
      " 4.45831476e-04 4.45831476e-04 5.57289345e-04 5.57289345e-04\n",
      " 6.68747214e-04 6.68747214e-04 7.80205082e-04 7.80205082e-04\n",
      " 8.91662951e-04 8.91662951e-04 1.11457869e-03 1.11457869e-03\n",
      " 1.33749443e-03 1.33749443e-03 1.44895230e-03 1.44895230e-03\n",
      " 1.89478377e-03 1.89478377e-03 2.00624164e-03 2.00624164e-03\n",
      " 2.22915738e-03 2.22915738e-03 2.34061525e-03 2.34061525e-03\n",
      " 3.12082033e-03 3.12082033e-03 3.45519394e-03 3.45519394e-03\n",
      " 3.78956754e-03 3.78956754e-03 4.90414623e-03 4.90414623e-03\n",
      " 5.68435132e-03 5.68435132e-03 5.79580918e-03 5.79580918e-03\n",
      " 6.35309853e-03 6.35309853e-03 7.69059296e-03 7.69059296e-03\n",
      " 8.24788230e-03 8.24788230e-03 9.02808738e-03 9.02808738e-03\n",
      " 9.91975033e-03 9.91975033e-03 1.03655818e-02 1.03655818e-02\n",
      " 1.04770397e-02 1.04770397e-02 1.60499331e-02 1.60499331e-02\n",
      " 1.00000000e+00]\n",
      "7.tpr:\n",
      "[0.00000000e+00 9.72762646e-04 8.75486381e-03 1.07003891e-02\n",
      " 1.75097276e-02 1.94552529e-02 2.72373541e-02 2.91828794e-02\n",
      " 5.44747082e-02 5.64202335e-02 6.12840467e-02 6.42023346e-02\n",
      " 6.61478599e-02 6.80933852e-02 7.00389105e-02 7.39299611e-02\n",
      " 7.58754864e-02 8.17120623e-02 8.36575875e-02 1.26459144e-01\n",
      " 1.28404669e-01 1.66342412e-01 1.68287938e-01 2.11089494e-01\n",
      " 2.13035019e-01 2.39299611e-01 2.41245136e-01 2.89883268e-01\n",
      " 2.91828794e-01 9.40661479e-01 9.40661479e-01 9.46498054e-01\n",
      " 9.46498054e-01 9.47470817e-01 9.47470817e-01 9.52334630e-01\n",
      " 9.52334630e-01 9.55252918e-01 9.55252918e-01 9.64007782e-01\n",
      " 9.64007782e-01 9.65953307e-01 9.65953307e-01 9.70817121e-01\n",
      " 9.70817121e-01 9.72762646e-01 9.72762646e-01 9.78599222e-01\n",
      " 9.78599222e-01 9.80544747e-01 9.80544747e-01 9.81517510e-01\n",
      " 9.81517510e-01 9.82490272e-01 9.82490272e-01 9.83463035e-01\n",
      " 9.83463035e-01 9.84435798e-01 9.84435798e-01 9.85408560e-01\n",
      " 9.85408560e-01 9.86381323e-01 9.86381323e-01 9.87354086e-01\n",
      " 9.87354086e-01 9.88326848e-01 9.88326848e-01 9.89299611e-01\n",
      " 9.89299611e-01 9.90272374e-01 9.90272374e-01 9.92217899e-01\n",
      " 9.92217899e-01 9.93190661e-01 9.93190661e-01 9.94163424e-01\n",
      " 9.94163424e-01 9.95136187e-01 9.95136187e-01 9.96108949e-01\n",
      " 9.96108949e-01 9.97081712e-01 9.97081712e-01 9.98054475e-01\n",
      " 9.98054475e-01 9.99027237e-01 9.99027237e-01 1.00000000e+00\n",
      " 1.00000000e+00]\n",
      "7.auc:\n",
      "0.9998580755346074\n",
      "8.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.10791048e-04\n",
      " 1.10791048e-04 2.21582096e-04 2.21582096e-04 3.32373144e-04\n",
      " 3.32373144e-04 4.43164192e-04 4.43164192e-04 6.64746288e-04\n",
      " 6.64746288e-04 7.75537337e-04 7.75537337e-04 8.86328385e-04\n",
      " 8.86328385e-04 9.97119433e-04 9.97119433e-04 1.21870153e-03\n",
      " 1.21870153e-03 1.32949258e-03 1.32949258e-03 1.77265677e-03\n",
      " 1.77265677e-03 1.88344782e-03 1.88344782e-03 1.99423887e-03\n",
      " 1.99423887e-03 2.76977620e-03 2.76977620e-03 3.43452249e-03\n",
      " 3.43452249e-03 3.54531354e-03 3.54531354e-03 4.98559716e-03\n",
      " 4.98559716e-03 5.20717926e-03 5.20717926e-03 8.42011965e-03\n",
      " 8.42011965e-03 8.86328385e-03 8.86328385e-03 1.47352094e-02\n",
      " 1.47352094e-02 1.99423887e-02 1.99423887e-02 3.12430756e-02\n",
      " 3.12430756e-02 1.32284511e-01 1.32284511e-01 2.07844006e-01\n",
      " 2.08065588e-01 4.18236207e-01 4.18457789e-01 1.00000000e+00]\n",
      "8.tpr:\n",
      "[0.         0.00102669 0.01334702 0.01540041 0.0338809  0.04004107\n",
      " 0.04209446 0.04414784 0.04620123 0.04825462 0.05030801 0.05338809\n",
      " 0.06262834 0.06468172 0.06673511 0.0687885  0.07700205 0.08110883\n",
      " 0.09445585 0.09650924 0.10164271 0.1036961  0.10677618 0.10882957\n",
      " 0.13141684 0.13347023 0.137577   0.13963039 0.14065708 0.14271047\n",
      " 0.14989733 0.15195072 0.17453799 0.17659138 0.19301848 0.19507187\n",
      " 0.19712526 0.19917864 0.20020534 0.20225873 0.28850103 0.29055441\n",
      " 0.29671458 0.29876797 0.31519507 0.31724846 0.33572895 0.33778234\n",
      " 0.33880903 0.34086242 0.39527721 0.3973306  0.41683778 0.41889117\n",
      " 0.42402464 0.42607803 0.64065708 0.64271047 0.9301848  0.9301848\n",
      " 0.94045175 0.94045175 0.94558522 0.94558522 0.95790554 0.95790554\n",
      " 0.96201232 0.96201232 0.9661191  0.9661191  0.96714579 0.96714579\n",
      " 0.96817248 0.96817248 0.97638604 0.97638604 0.97741273 0.97741273\n",
      " 0.98049281 0.98049281 0.9825462  0.9825462  0.98459959 0.98459959\n",
      " 0.98562628 0.98562628 0.98767967 0.98767967 0.99075975 0.99075975\n",
      " 0.99178645 0.99178645 0.99281314 0.99281314 0.99383984 0.99383984\n",
      " 0.99486653 0.99486653 0.99589322 0.99589322 0.99691992 0.99691992\n",
      " 0.99794661 0.99794661 0.99897331 0.99897331 1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "8.auc:\n",
      "0.999712671265443\n",
      "9.fpr:\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.11222333e-04 1.11222333e-04\n",
      " 2.22444667e-04 2.22444667e-04 3.33667000e-04 3.33667000e-04\n",
      " 4.44889334e-04 4.44889334e-04 5.56111667e-04 5.56111667e-04\n",
      " 6.67334001e-04 6.67334001e-04 7.78556334e-04 7.78556334e-04\n",
      " 8.89778668e-04 8.89778668e-04 1.33466800e-03 1.33466800e-03\n",
      " 1.55711267e-03 1.55711267e-03 1.77955734e-03 1.77955734e-03\n",
      " 1.89077967e-03 1.89077967e-03 2.11322434e-03 2.11322434e-03\n",
      " 2.33566900e-03 2.33566900e-03 2.55811367e-03 2.55811367e-03\n",
      " 3.22544767e-03 3.22544767e-03 3.78155934e-03 3.78155934e-03\n",
      " 4.11522634e-03 4.11522634e-03 5.56111667e-03 5.56111667e-03\n",
      " 6.22845067e-03 6.22845067e-03 6.33967301e-03 6.33967301e-03\n",
      " 6.56211767e-03 6.56211767e-03 7.00700701e-03 7.00700701e-03\n",
      " 8.45289734e-03 8.45289734e-03 1.01212323e-02 1.01212323e-02\n",
      " 1.30130130e-02 1.30130130e-02 1.32354577e-02 1.32354577e-02\n",
      " 1.42364587e-02 1.42364587e-02 1.50150150e-02 1.50150150e-02\n",
      " 2.38015794e-02 2.38015794e-02 2.46913580e-02 2.46913580e-02\n",
      " 4.30430430e-02 4.30430430e-02 7.57424091e-02 7.57424091e-02\n",
      " 1.00000000e+00]\n",
      "9.tpr:\n",
      "[0.00000000e+00 9.91080278e-04 4.95540139e-03 6.93756194e-03\n",
      " 1.68483647e-02 1.88305253e-02 2.08126858e-02 2.27948464e-02\n",
      " 5.64915758e-02 6.04558969e-02 6.34291378e-02 6.54112983e-02\n",
      " 6.83845391e-02 7.43310208e-02 7.63131814e-02 7.73042616e-02\n",
      " 7.92864222e-02 9.51437066e-02 9.71258672e-02 1.15956392e-01\n",
      " 1.17938553e-01 1.32804757e-01 1.35777998e-01 1.45688801e-01\n",
      " 1.47670961e-01 1.76412289e-01 1.78394450e-01 1.87314172e-01\n",
      " 1.89296333e-01 1.92269574e-01 1.94251734e-01 1.96233895e-01\n",
      " 1.98216056e-01 2.63627354e-01 2.65609514e-01 2.66600595e-01\n",
      " 2.68582755e-01 2.72547076e-01 2.74529237e-01 3.27056492e-01\n",
      " 3.29038652e-01 3.35976214e-01 3.37958375e-01 5.13379584e-01\n",
      " 5.15361744e-01 9.06838454e-01 9.06838454e-01 9.32606541e-01\n",
      " 9.32606541e-01 9.47472745e-01 9.47472745e-01 9.53419227e-01\n",
      " 9.53419227e-01 9.58374628e-01 9.58374628e-01 9.60356789e-01\n",
      " 9.60356789e-01 9.65312190e-01 9.65312190e-01 9.69276511e-01\n",
      " 9.69276511e-01 9.71258672e-01 9.71258672e-01 9.72249752e-01\n",
      " 9.72249752e-01 9.73240833e-01 9.73240833e-01 9.74231913e-01\n",
      " 9.74231913e-01 9.75222993e-01 9.75222993e-01 9.76214073e-01\n",
      " 9.76214073e-01 9.78196234e-01 9.78196234e-01 9.79187314e-01\n",
      " 9.79187314e-01 9.80178394e-01 9.80178394e-01 9.81169475e-01\n",
      " 9.81169475e-01 9.82160555e-01 9.82160555e-01 9.84142716e-01\n",
      " 9.84142716e-01 9.86124876e-01 9.86124876e-01 9.87115956e-01\n",
      " 9.87115956e-01 9.88107037e-01 9.88107037e-01 9.89098117e-01\n",
      " 9.89098117e-01 9.90089197e-01 9.90089197e-01 9.91080278e-01\n",
      " 9.91080278e-01 9.92071358e-01 9.92071358e-01 9.93062438e-01\n",
      " 9.93062438e-01 9.94053518e-01 9.94053518e-01 9.96035679e-01\n",
      " 9.96035679e-01 9.97026759e-01 9.97026759e-01 9.98017839e-01\n",
      " 9.98017839e-01 9.99008920e-01 9.99008920e-01 1.00000000e+00\n",
      " 1.00000000e+00]\n",
      "9.auc:\n",
      "0.9996564122761677\n",
      "\n",
      "Metric auc:\n",
      "------------------------------------------------\n",
      "0:\n",
      "0.9999411738087697\n",
      "1:\n",
      "0.9999644197967059\n",
      "2:\n",
      "0.9998790920689583\n",
      "3:\n",
      "0.9999363429112655\n",
      "4:\n",
      "0.9999427485829429\n",
      "5:\n",
      "0.9999270094196006\n",
      "6:\n",
      "0.9998479607343878\n",
      "7:\n",
      "0.9998580755346074\n",
      "8:\n",
      "0.999712671265443\n",
      "9:\n",
      "0.9996564122761677\n",
      "macro_avg:\n",
      "0.9998665906398848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create evaluator\n",
    "evaluator = EvaluatorDefault()\n",
    "\n",
    "# run\n",
    "results = evaluator.eval(ids=None,\n",
    "                    data=os.path.join(paths[\"inference_dir\"], eval_common_params[\"infer_filename\"]),\n",
    "                    metrics=metrics,\n",
    "                    output_dir=paths['eval_dir'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598f6cce495816406fbd34fea65bf7c807885b1496bf9be8c5dc5b47eac7d159"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38_tf2.3_pytorch1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
