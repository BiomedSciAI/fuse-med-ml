{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FuseMedML - Hello world\n",
    "Welcome!\\\n",
    "In this tutorial we'll cover the basics in our FuseMedML open soruce library through an hands-on notebook.\n",
    "\n",
    "Goals:\n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## FuseMedML\n",
    "[![Github repo](https://img.shields.io/static/v1?label=GitHub&message=FuseMedML&color=brightgreen)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/fuse-med-ml.svg)](https://badge.fury.io/py/fuse-med-ml)\n",
    "\n",
    "[![Slack channel](https://img.shields.io/badge/support-slack-slack.svg?logo=slack)](https://join.slack.com/t/fusemedml/shared_invite/zt-xr1jaj29-h7IMsSc0Lq4qpVNxW97Phw)\n",
    "\n",
    "[![Open Source](https://badges.frapsoft.com/os/v1/open-source.svg)](https://github.com/IBM/fuse-med-ml)\n",
    "\n",
    "\n",
    "FuseMedML is an open-source python-based framework designed to enhance collaboration and accelerate discoveries in Fused Medical data through advanced Machine Learning technologies. \n",
    "\n",
    "Initial version is PyTorch-based and focuses on deep learning on medical imaging.\n",
    "\n",
    "\n",
    "## **FuseMedML Key Concepts in a Nutshell**\n",
    "### Share and Reuse\n",
    "\n",
    "A common generic implementation, you can reuse, is provided for most components in the pipeline. \n",
    "\n",
    "The naming convention for the common implementation is `Fuse***Default` \n",
    "\n",
    "FuseMedML comes with a large collection of components that grow with each new project. Some of them are entirely generic and the others are domain specific.\n",
    "\n",
    "\n",
    "Don't forget to **contribute** back and **share** them. \n",
    "\n",
    "### Decoupling\n",
    "The decoupling is achieved by the fact that, in most cases, the objects do not interact directly. Instead, the information and data are routed between components using *namespaces* (examples below). \n",
    "\n",
    "Meaning, each object extracts its input from and saves its output into a dictionary named `batch_dict`. \n",
    "\n",
    "`batch_dict` aggregates the outputs of all the objects through a single batch. \n",
    "\n",
    "<br />\n",
    "\n",
    "**Example of the decoupling approach:**\n",
    "```python\n",
    "FuseMetricAUC(pred_name='model.output.classification', target_name='data.gt.classification')  \n",
    "```\n",
    "\n",
    "`FuseMetricAUC` will read the required tensors to compute AUC from `batch_dict`. The relevant dictionary keys are `pred_name` and `target_name`. \n",
    "\n",
    "This approach allows writing a generic metric which is completely independent of the model and data extractor. \n",
    "\n",
    "In addition, it allows to easily re-use this object in a plug & play manner without adding extra code. \n",
    "\n",
    "Such an approach also allows us to use it several times in case we have multiple heads/tasks.\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "When a batch is completed, only the required key-value pairs from `batch_dict`, such as the loss values, will be collected in another dictionary named `epoch_results`. \n",
    "\n",
    "Both `batch_dict` and `epoch_results` are nested dictionaries. To easily access the data stored in those dictionaries, use `FuseUtilsHierarchicalDict`:\n",
    "\n",
    "```python\n",
    "FuseUtilsHierarchicalDict.get(batch_dict, ‘model.output.classification’)\n",
    "``` \n",
    "\n",
    "will return `batch_dict[‘model’][‘output’][‘classification’]`\n",
    "\n",
    "### Manager API\n",
    "The manager is the main API while using Fuse - it resposible for the Train and Infer functionallity.\n",
    "\n",
    "Possible workflows are listed in the FuseMangerDefault's documentation. Here are two examples:\n",
    "\n",
    "##### **Train: Init -> set objects -> train**\n",
    "```python\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_common_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_common_params['manager.train_params'],\n",
    "                    output_model_dir=paths['model_dir'])\n",
    "\n",
    "manager.train(train_dataloader=train_dataloader,\n",
    "                validation_dataloader=validation_dataloader)\n",
    "```\n",
    "\n",
    "##### **Infer: Init -> infer**\n",
    "```python\n",
    "manager = FuseManagerDefault()\n",
    "\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Use PyTorch directly and alternative frameworks\n",
    "\n",
    "FuseMedML uses and extends PyTorch only when required by the user. \n",
    "You can mix FuseMedML with PyTorch code, components from alternative frameworks and other popular GitHub projects. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## **Installation Details - Google Colab**\n",
    "\n",
    "\n",
    "#### **Install FuseMedML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/fuse-med-ml.git\n",
    "# %cd fuse-med-ml\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Setup environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from fuse.eval.evaluator import EvaluatorDefault\n",
    "from fuse.data.dataset.dataset_wrapper import FuseDatasetWrapper\n",
    "from fuse.data.sampler.sampler_balanced_batch import FuseSamplerBalancedBatch\n",
    "from fuse.losses.loss_default import FuseLossDefault\n",
    "from fuse.managers.callbacks.callback_tensorboard import FuseTensorboardCallback\n",
    "from fuse.managers.manager_default import FuseManagerDefault\n",
    "from fuse.eval.metrics.classification.metrics_classification_common import MetricAccuracy, MetricAUCROC, MetricROCCurve\n",
    "from fuse.eval.metrics.classification.metrics_thresholding_common import MetricApplyThresholds\n",
    "from fuse.models.model_wrapper import FuseModelWrapper\n",
    "from fuse_examples.classification.mnist.lenet import LeNet\n",
    "from fuse_examples.tutorials.hello_world.hello_world_utils import perform_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Output paths**\n",
    "The user is able to customize the output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'examples' # TODO: fill path here\n",
    "PATHS = {'model_dir': os.path.join(ROOT, 'mnist/model_dir'),\n",
    "         'force_reset_model_dir': True,  # If True will reset model dir automatically - otherwise will prompt 'are you sure' message.\n",
    "         'cache_dir': os.path.join(ROOT, 'mnist/cache_dir'),\n",
    "         'inference_dir': os.path.join(ROOT, 'mnist/infer_dir'),\n",
    "         'eval_dir': os.path.join(ROOT, 'mnist/eval_dir')}\n",
    "\n",
    "paths = PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training Parameters**\n",
    "* Model - which model we are using.\n",
    "* Data - define parameters for the data preproccesing.\n",
    "* Manager - define parameters for the training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COMMON_PARAMS = {}\n",
    "\n",
    "### Model ###\n",
    "TRAIN_COMMON_PARAMS['model'] = 'lenet'\n",
    "\n",
    "### Data ###\n",
    "TRAIN_COMMON_PARAMS['data.batch_size'] = 100\n",
    "TRAIN_COMMON_PARAMS['data.train_num_workers'] = 8\n",
    "TRAIN_COMMON_PARAMS['data.validation_num_workers'] = 8\n",
    "\n",
    "### Manager ###\n",
    "TRAIN_COMMON_PARAMS['manager.train_params'] = {\n",
    "    'device': 'cuda', \n",
    "    'num_epochs': 5,\n",
    "    'virtual_batch_size': 1,  # number of batches in one virtual batch\n",
    "    'start_saving_epochs': 10,  # first epoch to start saving checkpoints from\n",
    "    'gap_between_saving_epochs': 5,  # number of epochs between saved checkpoint\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.best_epoch_source'] = {\n",
    "    'source': 'metrics.accuracy',  # can be any key from 'epoch_results'\n",
    "    'optimization': 'max',  # can be either min/max\n",
    "    'on_equal_values': 'better',\n",
    "    # can be either better/worse - whether to consider best epoch when values are equal\n",
    "}\n",
    "TRAIN_COMMON_PARAMS['manager.learning_rate'] = 1e-4\n",
    "TRAIN_COMMON_PARAMS['manager.weight_decay'] = 0.001\n",
    "TRAIN_COMMON_PARAMS['manager.resume_checkpoint_filename'] = None  # if not None, will try to load the checkpoint\n",
    "\n",
    "TRAIN_COMMON_PARAMS['manager.train_params']['device'] = 'cpu'\n",
    "\n",
    "train_params = TRAIN_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data**\n",
    "Downloading the MNIST dataset and building dataloaders (torch.utils.data.DataLoader) for both train and validation using Fuse components:\n",
    "1. Wrapper - **FuseDatasetWrapper**:\n",
    "\n",
    "    Wraps PyTorch dataset such that each sample is being converted to dictionary according to the provided mapping.\n",
    "2. Sampler - **FuseSamplerBalancedBatch**:\n",
    "\n",
    "    Implementing 'torch.utils.data.sampler'.\n",
    "    \n",
    "    The sampler retrieves list of samples to use for each batch.\n",
    "\n",
    "\n",
    "Other Fuse components for preprocessing data are:\n",
    "* FuseDataSourceBase\n",
    "* FuseProcessorBase\n",
    "* FuseDatasetBase\n",
    "* FuseAugmentorBase\n",
    "* FuseVisualizerBase\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "torch_train_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=True, transform=transform)\n",
    "\n",
    "# wrapping torch dataset\n",
    "train_dataset = FuseDatasetWrapper(name='train', dataset=torch_train_dataset, mapping=('image', 'label'))\n",
    "train_dataset.create()\n",
    "\n",
    "sampler = FuseSamplerBalancedBatch(dataset=train_dataset,\n",
    "                                balanced_class_name='data.label',\n",
    "                                num_balanced_classes=10,\n",
    "                                batch_size=train_params['data.batch_size'],\n",
    "                                balanced_class_weights=None)\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=train_params['data.train_num_workers'])\n",
    "\n",
    "## Validation data\n",
    "# Create dataset\n",
    "torch_validation_dataset = torchvision.datasets.MNIST(paths['cache_dir'], download=True, train=False, transform=transform)\n",
    "# wrapping torch dataset\n",
    "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_validation_dataset, mapping=('image', 'label'))\n",
    "validation_dataset.create()\n",
    "\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=train_params['data.batch_size'],\n",
    "                                num_workers=train_params['data.validation_num_workers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**\n",
    "Building the LeNet model using PyTorch's API and then wrapping it. \n",
    "\n",
    "The model outputs will be aggregated in batch_dict['model.*'].\n",
    "\n",
    "\n",
    "Another option to implement a model is to use Fuse components such as:\n",
    "* FuseModelDefault\n",
    "* FuseBackbone\n",
    "* FuseHead\n",
    "* FuseModelEnsemble\n",
    "* FuseModelMultistream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = LeNet()\n",
    "\n",
    "model = FuseModelWrapper(model=torch_model,\n",
    "                        model_inputs=['data.image'],\n",
    "                        post_forward_processing_function=perform_softmax,\n",
    "                        model_outputs=['logits.classification', 'output.classification']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loss function**\n",
    "Dictionary of loss elements. each element is a sub-class of FuseLossBase.\n",
    "\n",
    "The total loss will be the weighted sum of all the elements.\n",
    "\n",
    "#TODO: Elaborate what the it does: extract the label ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    'cls_loss': FuseLossDefault(pred_name='model.logits.classification', target_name='data.label', callable=F.cross_entropy, weight=1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Metrics**\n",
    "Dictionary of metric elements. Each element is a sub-class of FuseMetricBase.\n",
    "\n",
    "The metrics will be calculated per epoch for both the validation and train.\n",
    "\n",
    "The 'best_epoch_source', used to save the best model could be based on one of these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = OrderedDict([\n",
    "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')), # will apply argmax\n",
    "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred', target='data.label'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Callbacks**\n",
    "Callbacks are sub-classes of FuseCallbackBase.\n",
    "\n",
    "A callback is an object that can preform actions at various stages of training.\n",
    "\n",
    "In each stage it allows to manipulate either the data, batch_dict or epoch_results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    FuseTensorboardCallback(model_dir=paths['model_dir']),  # save statistics for tensorboard\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**\n",
    "Building Fuse's manager and supplying it PyTorch's optimizer and scheduler.\n",
    "\n",
    "Note that the manger is using the training paremeter that we've set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_params['manager.learning_rate'], weight_decay=train_params['manager.weight_decay'])\n",
    "\n",
    "# create scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "# train from scratch\n",
    "manager = FuseManagerDefault(output_model_dir=paths['model_dir'], force_reset=paths['force_reset_model_dir'])\n",
    "\n",
    "# Providing the objects required for the training process.\n",
    "manager.set_objects(net=model,\n",
    "                    optimizer=optimizer,\n",
    "                    losses=losses,\n",
    "                    metrics=metrics,\n",
    "                    best_epoch_source=train_params['manager.best_epoch_source'],\n",
    "                    lr_scheduler=scheduler,\n",
    "                    callbacks=callbacks,\n",
    "                    train_params=train_params['manager.train_params'])\n",
    "\n",
    "# Start training\n",
    "manager.train(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Infer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_COMMON_PARAMS = {}\n",
    "INFER_COMMON_PARAMS['infer_filename'] = 'validation_set_infer.gz'\n",
    "INFER_COMMON_PARAMS['checkpoint'] = 'best' \n",
    "\n",
    "infer_common_params = INFER_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Infer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(dataset=validation_dataset, collate_fn=validation_dataset.collate_fn, batch_size=2, num_workers=2)\n",
    "\n",
    "## Manager for inference\n",
    "manager = FuseManagerDefault()\n",
    "output_columns = ['model.output.classification', 'data.label']\n",
    "manager.infer(data_loader=validation_dataloader,\n",
    "                input_model_dir=paths['model_dir'],\n",
    "                checkpoint=infer_common_params['checkpoint'],\n",
    "                output_columns=output_columns,\n",
    "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define EVAL Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_COMMON_PARAMS = {}\n",
    "EVAL_COMMON_PARAMS['infer_filename'] = INFER_COMMON_PARAMS['infer_filename']\n",
    "eval_common_params = EVAL_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Calculate metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "# metrics\n",
    "metrics = OrderedDict([\n",
    "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')), # will apply argmax\n",
    "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred', target='data.label')),\n",
    "    ('roc', MetricROCCurve(pred='model.output.classification', target='data.label', class_names=class_names, output_filename=os.path.join(paths['inference_dir'], 'roc_curve.png'))),\n",
    "    ('auc', MetricAUCROC(pred='model.output.classification', target='data.label', class_names=class_names)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evaluator\n",
    "evaluator = EvaluatorDefault()\n",
    "\n",
    "# run\n",
    "results = evaluator.eval(ids=None,\n",
    "                    data=os.path.join(paths[\"inference_dir\"], eval_common_params[\"infer_filename\"]),\n",
    "                    metrics=metrics,\n",
    "                    output_dir=paths['eval_dir'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598f6cce495816406fbd34fea65bf7c807885b1496bf9be8c5dc5b47eac7d159"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py38_tf2.3_pytorch1.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
