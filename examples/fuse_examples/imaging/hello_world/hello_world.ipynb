{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FuseMedML - Hello World\n",
    "[![Github repo](https://img.shields.io/static/v1?label=GitHub&message=FuseMedML&color=brightgreen)](https://github.com/BiomedSciAI/fuse-med-ml)\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/fuse-med-ml.svg)](https://badge.fury.io/py/fuse-med-ml)\n",
    "\n",
    "[![Slack channel](https://img.shields.io/badge/support-slack-slack.svg?logo=slack)](https://join.slack.com/t/fusemedml/shared_invite/zt-xr1jaj29-h7IMsSc0Lq4qpVNxW97Phw)\n",
    "\n",
    "[![Open Source](https://badges.frapsoft.com/os/v1/open-source.svg)](https://github.com/BiomedSciAI/fuse-med-ml)\n",
    "\n",
    "\n",
    "**Welcome to FuseMedML's 'hello world' hands-on notebook!**\n",
    "\n",
    "In this notebook we'll examine a FuseMedML's basic use case: MNIST multiclass classification - incluing training, inference and evaluation.\n",
    "\n",
    "By the end of the session we hope you'll be familiar with basic Fuse's workflow and acknowledge it's potential.\n",
    "\n",
    "Open and run this notebook in [Google Colab](https://colab.research.google.com/github/BiomedSciAI/fuse-med-ml/blob/master/examples/fuse_examples/imaging/hello_world/hello_world.ipynb)\n",
    "\n",
    "ENJOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## **Installation Details - Google Colab**\n",
    "\n",
    "\n",
    "#### **Install FuseMedML**\n",
    "If fuse-med-ml package is already cloned and installed this should be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_fuse = False  # 'True' to clone and install fuse-med-ml.\n",
    "use_gpu = True  # 'False' in order to use cpu.\n",
    "\n",
    "if install_fuse:\n",
    "    !git clone https://github.com/BiomedSciAI/fuse-med-ml.git\n",
    "    %cd fuse-med-ml\n",
    "    !pip install -e .[all]\n",
    "    !pip install -e examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Setup environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from typing import OrderedDict\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from fuse.eval.evaluator import EvaluatorDefault\n",
    "from fuse.dl.losses.loss_default import LossDefault\n",
    "from fuse.eval.metrics.classification.metrics_classification_common import MetricAccuracy, MetricAUCROC, MetricROCCurve\n",
    "from fuse.eval.metrics.classification.metrics_thresholding_common import MetricApplyThresholds\n",
    "from fuse.dl.models.model_wrapper import ModelWrapSeqToDict\n",
    "from fuse.data.utils.samplers import BatchSamplerDefault\n",
    "from fuse.data.utils.collates import CollateDefault\n",
    "from fuse.dl.lightning.pl_module import LightningModuleDefault\n",
    "from fuse.dl.lightning.pl_funcs import convert_predictions_to_dataframe\n",
    "from fuse.utils.file_io.file_io import create_dir, save_dataframe\n",
    "from fuseimg.datasets.mnist import MNIST\n",
    "\n",
    "\n",
    "# ugly workaround - for details: https://stackoverflow.com/questions/57831187/need-to-restart-runtime-before-import-an-installed-package-in-colab\n",
    "try:\n",
    "  from fuse_examples.imaging.hello_world.hello_world_utils import LeNet, perform_softmax\n",
    "except ImportError:\n",
    "  print('Stopping RUNTIME. Colaboratory will restart automatically. Please run again.')\n",
    "  exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Output paths**\n",
    "The user is able to easily customize the directories paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"_examples/mnist\"\n",
    "model_dir = os.path.join(ROOT, \"model_dir\")\n",
    "PATHS = {\n",
    "    \"model_dir\": model_dir,\n",
    "    \"cache_dir\": os.path.join(ROOT, \"cache_dir\"),\n",
    "    \"inference_dir\": os.path.join(model_dir, \"infer_dir\"),\n",
    "    \"eval_dir\": os.path.join(model_dir, \"eval_dir\"),\n",
    "}\n",
    "\n",
    "paths = PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_COMMON_PARAMS = {}\n",
    "\n",
    "### Data ###\n",
    "TRAIN_COMMON_PARAMS[\"data.batch_size\"] = 100\n",
    "TRAIN_COMMON_PARAMS[\"data.train_num_workers\"] = 8\n",
    "TRAIN_COMMON_PARAMS[\"data.validation_num_workers\"] = 8\n",
    "\n",
    "### PL Trainer ###\n",
    "TRAIN_COMMON_PARAMS[\"trainer.num_epochs\"] = 2\n",
    "TRAIN_COMMON_PARAMS[\"trainer.num_devices\"] = 1\n",
    "TRAIN_COMMON_PARAMS[\"trainer.accelerator\"] = \"gpu\" if use_gpu else \"cpu\"\n",
    "TRAIN_COMMON_PARAMS[\"trainer.ckpt_path\"] = None  #  path to the checkpoint you wish continue the training from\n",
    "\n",
    "### Optimizer ###\n",
    "TRAIN_COMMON_PARAMS[\"opt.lr\"] = 1e-4\n",
    "TRAIN_COMMON_PARAMS[\"opt.weight_decay\"] = 0.001\n",
    "\n",
    "train_params = TRAIN_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data**\n",
    "Downloading the MNIST dataset and building dataloaders (torch.utils.data.DataLoader) for both train and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d7e571aa7f4c37ae40d1685e0bf228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting _examples/mnist/cache_dir/MNIST/raw/train-images-idx3-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f4baf390c64d6e92064fa215db2fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting _examples/mnist/cache_dir/MNIST/raw/train-labels-idx1-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66c9385bc6249829bed7525a4181de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting _examples/mnist/cache_dir/MNIST/raw/t10k-images-idx3-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2802500b134c7694c9d2a7189e659d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting _examples/mnist/cache_dir/MNIST/raw/t10k-labels-idx1-ubyte.gz to _examples/mnist/cache_dir/MNIST/raw\n",
      "\n",
      "\u001b[36mmultiprocess pool created with 10 workers.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch_sampler: 100%|██████████| 60000/60000 [00:08<00:00, 7394.27it/s]\n"
     ]
    }
   ],
   "source": [
    "## Training Data\n",
    "# Create dataset\n",
    "train_dataset = MNIST.dataset(paths[\"cache_dir\"], train=True)\n",
    "\n",
    "# Create Fuse's custom sampler\n",
    "sampler = BatchSamplerDefault(\n",
    "    dataset=train_dataset,\n",
    "    balanced_class_name=\"data.label\",\n",
    "    num_balanced_classes=10,\n",
    "    batch_size=train_params[\"data.batch_size\"],\n",
    "    balanced_class_weights=None,\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_sampler=sampler,\n",
    "    collate_fn=CollateDefault(),\n",
    "    num_workers=train_params[\"data.train_num_workers\"],\n",
    ")\n",
    "\n",
    "## Validation data\n",
    "# Create dataset\n",
    "validation_dataset = MNIST.dataset(paths[\"cache_dir\"], train=False)\n",
    "\n",
    "# dataloader\n",
    "validation_dataloader = DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=train_params[\"data.batch_size\"],\n",
    "    collate_fn=CollateDefault(),\n",
    "    num_workers=train_params[\"data.validation_num_workers\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model**\n",
    "Building a LeNet model using \"pure\" PyTorch and wrapping it with Fuse's component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    torch_model = LeNet()\n",
    "    # wrap basic torch model to automatically read inputs from batch_dict and save its outputs to batch_dict\n",
    "    model = ModelWrapSeqToDict(\n",
    "        model=torch_model,\n",
    "        model_inputs=[\"data.image\"],\n",
    "        post_forward_processing_function=perform_softmax,\n",
    "        model_outputs=[\"model.logits.classification\", \"model.output.classification\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Loss function**\n",
    "Dictionary of loss elements such that each element is a sub-class of LossBase. The total loss will be the weighted sum of all the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    \"cls_loss\": LossDefault(\n",
    "        pred=\"model.logits.classification\", target=\"data.label\", callable=F.cross_entropy, weight=1.0\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Metrics**\n",
    "Dictionary of metric elements such that each element is a sub-class of MetricBase.\n",
    "\n",
    "The metrics will be calculated per epoch for both the validation and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = OrderedDict(\n",
    "    [\n",
    "        (\"operation_point\", MetricApplyThresholds(pred=\"model.output.classification\")),  # will apply argmax\n",
    "        (\"accuracy\", MetricAccuracy(pred=\"results:metrics.operation_point.cls_pred\", target=\"data.label\")),\n",
    "    ]\n",
    ")\n",
    "validation_metrics = copy.deepcopy(train_metrics)  # use the same metrics in validation as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Best Epoch Source**\n",
    "Defining what will be considered as 'the best epoch' so the model will be saved according to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_source = dict(monitor=\"validation.metrics.accuracy\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Train**\n",
    "Training session using PyTorch Lightning's trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "No supported gpu backend found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     12\u001b[0m pl_module \u001b[39m=\u001b[39m LightningModuleDefault(\n\u001b[1;32m     13\u001b[0m     model_dir\u001b[39m=\u001b[39mpaths[\u001b[39m\"\u001b[39m\u001b[39mmodel_dir\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     optimizers_and_lr_schs\u001b[39m=\u001b[39moptimizers_and_lr_schs,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[39m# create lightining trainer\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m pl_trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(\n\u001b[1;32m     24\u001b[0m     default_root_dir\u001b[39m=\u001b[39;49mpaths[\u001b[39m\"\u001b[39;49m\u001b[39mmodel_dir\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     25\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mtrain_params[\u001b[39m\"\u001b[39;49m\u001b[39mtrainer.num_epochs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     26\u001b[0m     accelerator\u001b[39m=\u001b[39;49mtrain_params[\u001b[39m\"\u001b[39;49m\u001b[39mtrainer.accelerator\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     27\u001b[0m     devices\u001b[39m=\u001b[39;49mtrain_params[\u001b[39m\"\u001b[39;49m\u001b[39mtrainer.num_devices\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     28\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[1;32m     32\u001b[0m pl_trainer\u001b[39m.\u001b[39mfit(pl_module, train_dataloader, validation_dataloader, ckpt_path\u001b[39m=\u001b[39mtrain_params[\u001b[39m\"\u001b[39m\u001b[39mtrainer.ckpt_path\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/dccstor/mm_hcls/usr/sagi/anaconda3/envs/fuse_repo_3/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py:345\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    344\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/dccstor/mm_hcls/usr/sagi/anaconda3/envs/fuse_repo_3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:433\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> 433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    434\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    435\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    436\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    437\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    438\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    439\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    440\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    441\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    442\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    443\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    444\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    445\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    446\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[1;32m    447\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    448\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    449\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    450\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    451\u001b[0m )\n\u001b[1;32m    452\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m)\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/dccstor/mm_hcls/usr/sagi/anaconda3/envs/fuse_repo_3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:212\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_auto_accelerator()\n\u001b[1;32m    211\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_choose_gpu_accelerator_backend()\n\u001b[1;32m    214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_parallel_devices_and_init_accelerator()\n\u001b[1;32m    216\u001b[0m \u001b[39m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n",
      "File \u001b[0;32m/dccstor/mm_hcls/usr/sagi/anaconda3/envs/fuse_repo_3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:518\u001b[0m, in \u001b[0;36mAcceleratorConnector._choose_gpu_accelerator_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m CUDAAccelerator\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 518\u001b[0m \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mNo supported gpu backend found!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: No supported gpu backend found!"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=train_params[\"opt.lr\"], weight_decay=train_params[\"opt.weight_decay\"])\n",
    "\n",
    "# create scheduler\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "lr_sch_config = dict(scheduler=lr_scheduler, monitor=\"validation.losses.total_loss\")\n",
    "\n",
    "# optimizer and lr sch - see pl.LightningModule.configure_optimizers return value for all options\n",
    "optimizers_and_lr_schs = dict(optimizer=optimizer, lr_scheduler=lr_sch_config)\n",
    "\n",
    "# create instance of PL module - FuseMedML generic version\n",
    "pl_module = LightningModuleDefault(\n",
    "    model_dir=paths[\"model_dir\"],\n",
    "    model=model,\n",
    "    losses=losses,\n",
    "    train_metrics=train_metrics,\n",
    "    validation_metrics=validation_metrics,\n",
    "    best_epoch_source=best_epoch_source,\n",
    "    optimizers_and_lr_schs=optimizers_and_lr_schs,\n",
    ")\n",
    "\n",
    "# create lightning trainer\n",
    "pl_trainer = pl.Trainer(\n",
    "    default_root_dir=paths[\"model_dir\"],\n",
    "    max_epochs=train_params[\"trainer.num_epochs\"],\n",
    "    accelerator=train_params[\"trainer.accelerator\"],\n",
    "    devices=train_params[\"trainer.num_devices\"],\n",
    "    auto_select_gpus=True,\n",
    ")\n",
    "\n",
    "# train\n",
    "pl_trainer.fit(pl_module, train_dataloader, validation_dataloader, ckpt_path=train_params[\"trainer.ckpt_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Infer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define Infer Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_COMMON_PARAMS = {}\n",
    "INFER_COMMON_PARAMS[\"infer_filename\"] = \"infer_file.gz\"\n",
    "INFER_COMMON_PARAMS[\"checkpoint\"] = \"best_epoch.ckpt\"\n",
    "INFER_COMMON_PARAMS[\"trainer.num_devices\"] = TRAIN_COMMON_PARAMS[\"trainer.num_devices\"]\n",
    "INFER_COMMON_PARAMS[\"trainer.accelerator\"] = TRAIN_COMMON_PARAMS[\"trainer.accelerator\"]\n",
    "\n",
    "infer_common_params = INFER_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Infer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting dir and paths\n",
    "create_dir(paths[\"inference_dir\"])\n",
    "infer_file = os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"])\n",
    "checkpoint_file = os.path.join(paths[\"model_dir\"], infer_common_params[\"checkpoint\"])\n",
    "\n",
    "# creating a dataloader\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, collate_fn=CollateDefault(), batch_size=2, num_workers=2)\n",
    "\n",
    "# load pytorch lightning module\n",
    "model = create_model()\n",
    "pl_module = LightningModuleDefault.load_from_checkpoint(\n",
    "    checkpoint_file, model_dir=paths[\"model_dir\"], model=model, map_location=\"cpu\", strict=True\n",
    ")\n",
    "\n",
    "# set the prediction keys to extract (the ones used be the evaluation function).\n",
    "pl_module.set_predictions_keys(\n",
    "    [\"model.output.classification\", \"data.label\"]\n",
    ")  # which keys to extract and dump into file\n",
    "\n",
    "# create a trainer instance\n",
    "pl_trainer = pl.Trainer(\n",
    "    default_root_dir=paths[\"model_dir\"],\n",
    "    accelerator=infer_common_params[\"trainer.accelerator\"],\n",
    "    devices=infer_common_params[\"trainer.num_devices\"],\n",
    "    auto_select_gpus=True,\n",
    ")\n",
    "\n",
    "# predict\n",
    "predictions = pl_trainer.predict(pl_module, validation_dataloader, return_predictions=True)\n",
    "\n",
    "# convert list of batch outputs into a dataframe\n",
    "infer_df = convert_predictions_to_dataframe(predictions)\n",
    "save_dataframe(infer_df, infer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**\n",
    "Using the `EvaluatorDefault` from the evaluation package of FuseMedML (fuse.eval) which is a standalone library for evaluating ML models that not necessarily trained with FuseMedML.\n",
    "\n",
    "More details and examples for the evaluation package can be found [here](https://github.com/BiomedSciAI/fuse-med-ml/blob/master/fuse/eval/README.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define EVAL Common Params**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_COMMON_PARAMS = {}\n",
    "EVAL_COMMON_PARAMS[\"infer_filename\"] = INFER_COMMON_PARAMS[\"infer_filename\"]\n",
    "\n",
    "eval_common_params = EVAL_COMMON_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Define metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "# metrics\n",
    "metrics = OrderedDict(\n",
    "    [\n",
    "        (\"operation_point\", MetricApplyThresholds(pred=\"model.output.classification\")),  # will apply argmax\n",
    "        (\"accuracy\", MetricAccuracy(pred=\"results:metrics.operation_point.cls_pred\", target=\"data.label\")),\n",
    "        (\n",
    "            \"roc\",\n",
    "            MetricROCCurve(\n",
    "                pred=\"model.output.classification\",\n",
    "                target=\"data.label\",\n",
    "                class_names=class_names,\n",
    "                output_filename=os.path.join(paths[\"inference_dir\"], \"roc_curve.png\"),\n",
    "            ),\n",
    "        ),\n",
    "        (\"auc\", MetricAUCROC(pred=\"model.output.classification\", target=\"data.label\", class_names=class_names)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evaluator\n",
    "evaluator = EvaluatorDefault()\n",
    "\n",
    "# run eval\n",
    "results = evaluator.eval(\n",
    "    ids=None,\n",
    "    data=os.path.join(paths[\"inference_dir\"], eval_common_params[\"infer_filename\"]),\n",
    "    metrics=metrics,\n",
    "    output_dir=paths[\"eval_dir\"],\n",
    ")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes\n",
    "test_result_acc = results[\"metrics.accuracy\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuse_repo_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "603ef3845b02b84c8b743302232442c478ebfea21d9503b404b4c0a993eb87a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
