{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e240708",
   "metadata": {},
   "source": [
    "# Data Package\n",
    "Extremely flexible pipeline allowing data loading, processing, and augmentation suitable for machine learning experiments. Supports caching to avoid redundant calculations and to speed up research iteration times significantly. The data package comes with a rich collection of pre-implemented operations and utilities that facilitates data processing. \n",
    "\n",
    "## Terminology\n",
    "\n",
    "**sample_dict** - Represents a single sample and contains all relevant information about the sample.\n",
    "\n",
    "No specific structure of this dictionary is required, but a useful pattern is to split it into sections (keys that define a \"namespace\" ): such as \"data\", \"model\",  etc.\n",
    "NDict (fuse/utils/ndict.py) class is used instead of python standard dictionary in order to allow easy \".\" seperated access. For example:\n",
    "`sample_dict[“data.input.img”]` is the equivallent of `sample_dict[\"data\"][\"input\"][\"img\"]`\n",
    "\n",
    "Another recommended convention is to include suffix specifying the type of the value (\"img\", \"seg\", \"bbox\")\n",
    "\n",
    "\n",
    "**sample_id** - a unique identifier of a sample. Each sample in the dataset must have an id that uniquely identifies it.\n",
    "Examples of sample ids:\n",
    "* path to the image file\n",
    "* Tuple of (provider_id, patient_id, image_id)\n",
    "* Running index\n",
    "\n",
    "The unique identifier will be stored in sample_dict[\"data.sample_id\"]\n",
    "\n",
    "## Op(erator)\n",
    "\n",
    "Operators are the building blocks of the sample processing pipeline. Each operator gets as input the *sample_dict* as created by the previous operators and can either add/delete/modify fields in sample_dict. The operator interface is specified in OpBase class. \n",
    "A pipeline is built as a sequence of operators, which do everything - loading a new sample, preprocessing, augmentation, and more.\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "A sequence of operators loading, pre-processing, and augmenting a sample. We split the pipeline into two parts - static and dynamic, which allow us to control the part out of the entire pipeline that will be cached. To learn more see *Adding a dynamic part*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df330722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuse.data.pipelines.pipeline_default import PipelineDefault\n",
    "from fuse.data.datasets.dataset_default import DatasetDefault\n",
    "from fuse.data.ops.op_base import OpBase\n",
    "from fuse.data.ops.ops_aug_common import OpSample\n",
    "from fuse.data.datasets.caching.samples_cacher import SamplesCacher\n",
    "from fuse.data.ops.ops_common import OpLambda\n",
    "from fuse.data.utils.samplers import BatchSamplerDefault\n",
    "from fuse.data import PipelineDefault, OpSampleAndRepeat, OpToTensor, OpRepeat\n",
    "from fuse.utils.rand.param_sampler import RandBool, RandInt, Uniform\n",
    "import torch\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "import os\n",
    "from fuse.data.ops.ops_cast import OpToTensor\n",
    "from fuse.utils.ndict import NDict\n",
    "from fuseimg.data.ops.image_loader import OpLoadImage \n",
    "from fuseimg.data.ops.color import OpClip, OpToRange\n",
    "from fuseimg.data.ops.aug.color import OpAugColor\n",
    "from fuseimg.data.ops.aug.geometry import OpAugAffine2D\n",
    "\n",
    "from fuseimg.datasets.kits21 import OpKits21SampleIDDecode, KITS21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a0b1a",
   "metadata": {},
   "source": [
    "## Basic example - a static pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d12c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples = 2\n",
    "data_dir = os.environ[\"KITS21_DATA_PATH\"] if \"KITS21_DATA_PATH\" in os.environ else mkdtemp(prefix=\"kits21_data\")\n",
    "KITS21.download(data_dir, cases=list(range(num_samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_pipeline = PipelineDefault(\"static\", [\n",
    "    # decoding sample ID\n",
    "    (OpKits21SampleIDDecode(), dict()), # will save image and seg path to \"data.input.img_path\", \"data.gt.seg_path\" \n",
    "\n",
    "    # loading data\n",
    "    (OpLoadImage(data_dir), dict(key_in=\"data.input.img_path\", key_out=\"data.input.img\", format=\"nib\")),\n",
    "    (OpLoadImage(data_dir), dict(key_in=\"data.gt.seg_path\", key_out=\"data.gt.seg\", format=\"nib\")),\n",
    "\n",
    "\n",
    "    # fixed image normalization\n",
    "    (OpClip(), dict(key=\"data.input.img\", clip=(-500, 500))),\n",
    "    (OpToRange(), dict(key=\"data.input.img\", from_range=(-500, 500), to_range=(0, 1))),\n",
    "])\n",
    "sample_ids=[f\"case_{id:05d}\" for id in range(num_samples)]\n",
    "my_dataset = DatasetDefault(sample_ids=sample_ids,\n",
    "    static_pipeline=static_pipeline,           \n",
    ")\n",
    "my_dataset.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3309180",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"min = {np.min(my_dataset[0]['data.input.img'])} | max = {np.max(my_dataset[0]['data.input.img'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset[0][\"data.input.img\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22514dcb",
   "metadata": {},
   "source": [
    "A basic example, including static pipeline only that loading and pre-processing an image and a corresponding segmentation map. \n",
    "A pipeline is created from a list of tuples. Each tuple includes an op and op arguments. The required arguments for an op specified in its \\_\\_call\\_\\_() method.\n",
    "In this example \"sample_id\" is a running index. OpKits21SampleIDDecode() is a custom op converting the index to image path and segmentation path which then loaded by OpImageLoad(). Finally, OpClip() and OpToRange() pre-process the image.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0c6c9",
   "metadata": {},
   "source": [
    "## Caching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3340ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids=[f\"case_{id:05d}\" for id in range(num_samples)]\n",
    "\n",
    "static_pipeline = PipelineDefault(\"static\", [\n",
    "    (OpKits21SampleIDDecode(), dict()),\n",
    "    (OpLoadImage(data_dir), dict(key_in=\"data.input.img_path\", key_out=\"data.input.img\", format=\"nib\")),\n",
    "    (OpLoadImage(data_dir), dict(key_in=\"data.gt.seg_path\", key_out=\"data.gt.seg\", format=\"nib\")),\n",
    "    ])\n",
    "\n",
    "\n",
    "cache_dir = mkdtemp(prefix=\"kits_21\")\n",
    "cacher = SamplesCacher(f'kits21_cache_ver{KITS21.KITS21_DATASET_VER}', \n",
    "    static_pipeline,\n",
    "    cache_dirs=[cache_dir], restart_cache=True)   \n",
    "\n",
    "my_dataset = DatasetDefault(sample_ids=sample_ids,\n",
    "    static_pipeline=static_pipeline,\n",
    "    dynamic_pipeline=None,\n",
    "    cacher=cacher,            \n",
    ")\n",
    "my_dataset.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e24fe",
   "metadata": {},
   "source": [
    "To enable caching, a sample cacher should be created and specified as in the example above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc170f6",
   "metadata": {},
   "source": [
    "## Adding a dynamic part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a5c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_pipeline = PipelineDefault(\"dynamic\", [\n",
    "    (OpClip(), dict(key=\"data.input.img\", clip=(-500,500))),\n",
    "    (OpToRange(), dict(key=\"data.input.img\", from_range=(-500, 500), to_range=(0, 1))),\n",
    "])\n",
    "my_dataset = DatasetDefault(sample_ids=sample_ids,\n",
    "    static_pipeline=static_pipeline,\n",
    "    dynamic_pipeline=dynamic_pipeline,\n",
    "    cacher=cacher,            \n",
    ")\n",
    "my_dataset.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset[0][\"data.input.img\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af3cac",
   "metadata": {},
   "source": [
    "\n",
    "A basic example that includes both dynamic pipeline and static pipeline. Dynamic pipeline follows the static pipeline and continues to pre-process the sample. In contrast to the static pipeline, the output of the dynamic pipeline is not be cached and allows modifying the pre-precessing steps without recaching, The recommendation is to include pre-processing steps that we intend to experiment with, in the dynamic pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce87fc",
   "metadata": {},
   "source": [
    "### Avoiding boilerplate by using \"Meta Ops\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_for = [dict(key=\"data.input.img\"), dict(key=\"data.gt.seg\")]\n",
    "\n",
    "dynamic_pipeline = PipelineDefault(\"dynamic\", [\n",
    "    (OpClip(), dict(key=\"data.input.img\", clip=(-500,500))),\n",
    "    (OpToRange(), dict(key=\"data.input.img\", from_range=(-500, 500), to_range=(0, 1))),\n",
    "    (OpRepeat(OpToTensor(), kwargs_per_step_to_add=repeat_for), dict(dtype=torch.float32)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = DatasetDefault(sample_ids=sample_ids,\n",
    "    static_pipeline=static_pipeline,\n",
    "    dynamic_pipeline=dynamic_pipeline,\n",
    "    cacher=cacher,            \n",
    ")\n",
    "my_dataset.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(my_dataset[0][\"data.gt.seg\"], torch.Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9886d",
   "metadata": {},
   "source": [
    "Meta op is a powerful tool, Meta ops enhance the functionality and flexibility of the pipeline and allows avoiding boilerplate code,\n",
    "The example above is the simplest. We use OpRepeat to repeat OpToTensor twice, once for the image and once for the segmentation map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bbf333",
   "metadata": {},
   "source": [
    "## Adding augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_pipeline = PipelineDefault(\"dynamic\", [\n",
    "    (OpClip(), dict(key=\"data.input.img\", clip=(-500,500))),\n",
    "    (OpToRange(), dict(key=\"data.input.img\", from_range=(-500, 500), to_range=(0, 1))),\n",
    "    (OpRepeat(OpToTensor(), kwargs_per_step_to_add=repeat_for), dict(dtype=torch.float32)),\n",
    "    (OpSampleAndRepeat(OpAugAffine2D(), kwargs_per_step_to_add=repeat_for), dict(\n",
    "                    rotate=Uniform(-180.0,180.0),        \n",
    "                    scale=Uniform(0.8, 1.2),\n",
    "                    flip=(RandBool(0.5), RandBool(0.5)),\n",
    "                    translate=(RandInt(-15, 15), RandInt(-15, 15))\n",
    "                )),\n",
    "])\n",
    "my_dataset = DatasetDefault(sample_ids=sample_ids,\n",
    "    static_pipeline=static_pipeline,\n",
    "    dynamic_pipeline=dynamic_pipeline,\n",
    "    cacher=cacher,            \n",
    ")\n",
    "my_dataset.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"min = {torch.min(my_dataset[0]['data.input.img'])} | max = {torch.max(my_dataset[0]['data.input.img'])}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373b373",
   "metadata": {},
   "source": [
    "FuseMedML comes with a collection of pre-implemented augmentation ops. Augmentation ops are expected to be included in the dynamic_pipeline to avoid caching and to be called with different random numbers drawn from the specified distribution. In this example, we've added identical affine transformation for the image and segmentation map. OpSampleAndRepeat() will first draw the random numbers from the random arguments and then repeat OpAffineTransform2D for both the image and segmentation map with the same arguments.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61377338",
   "metadata": {},
   "source": [
    "## Using custom functions directly (OpFunc and OpLambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids=[f\"case_{id:05d}\" for id in range(num_samples)]\n",
    "repeat_for = [dict(key=\"data.input.img\"), dict(key=\"data.gt.seg\")]\n",
    "\n",
    "static_pipeline = PipelineDefault(\"static\", [\n",
    "    (OpKits21SampleIDDecode(), dict()),\n",
    "    (OpLoadImage(data_dir), dict(key_in=\"data.input.img_path\", key_out=\"data.input.img\", format=\"nib\")),\n",
    "    (OpLoadImage(data_dir), dict(key_in=\"data.gt.seg_path\", key_out=\"data.gt.seg\", format=\"nib\")),\n",
    "    (OpRepeat(OpLambda(func=lambda x: np.reshape(x,(x.shape[0], 4, 256, 256))), repeat_for), dict())\n",
    "])\n",
    "my_dataset = DatasetDefault(sample_ids=sample_ids,\n",
    "    static_pipeline=static_pipeline,        \n",
    ")\n",
    "my_dataset.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset[0][\"data.gt.seg\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16ffb9",
   "metadata": {},
   "source": [
    "Pre-processing a dataset many times involves heuristics and custom functions. OpLambda and OpFunc allow using those functions directly instead of implementing Op for every custom function. This is a simple example of implementing NumPy array reshape using OpLambda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0da75",
   "metadata": {},
   "source": [
    "## Op(erators) list\n",
    "\n",
    "**Meta operators**\n",
    "\n",
    "Meta operators are a great tool to facilitate the development of sample processing pipelines.\n",
    "The following operators are useful when implementing a common pipeline:\n",
    "\n",
    "*\tOpRepeat - repeats an op multiple times, each time with different arguments\n",
    "*   OpLambda - applies simple lambda function / function to transform single value\n",
    "*   OpFunc - helps to wrap an existing simple python function without writing boilerplate code\n",
    "*   OpApplyPatterns - selects and applies an operation according to the key name in sample_dict.\n",
    "*   OpApplyTypes - selects and apply an operation according to value type (inferred from the key name in sample_dict)\n",
    "*   OpCollectMarker - use this op within the dynamic pipeline to optimize the reading time for components such as sampler \n",
    "\n",
    "**Meta operators for random augmentations**\n",
    "\n",
    "*\tOpSample - recursively searches for ParamSamplerBase instances in kwargs, and replaces the drawn values in place\n",
    "*   OpSampleAndRepeat - first samples and then repeats the operation with the drawn values. Used to apply the same transformation on different values such as image and segmentation map\n",
    "*   OpRepeatAndSample - repeats the operations, but each time has drawn different values from the defined distributions\n",
    "*\tOpRandApply - randomly applies the op (according to the given probability) \n",
    "\n",
    "**Reading operators**\n",
    "\n",
    "* OpReadDataframe - reads data from pickle file / Dataframe object. Each row will be added as a value to sample_dict\n",
    "\n",
    "**Casting operators**\n",
    "\n",
    "* OpToNumpy - convert many different types to NumPy array\n",
    "* OpToTensor - convert many different types to PyTorch tensor\n",
    "\n",
    "**Imaging operators**\n",
    "See fuseimg package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe6efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fe7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
